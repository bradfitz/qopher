{
	"description": "runtime: use lock-free ring for work scheduling\n\nThe algorithm used is based on the implementation in Concurrency Kit\n(http://concurrencykit.org). The ring has single producer, multiple\nconsumer access semantics; is wait-free on insert and lock-free on\nretrieval. The size must be a power of 2. This changeset removes the\nwork stealing code; it may be possible to add that back, but it is a\nbit hairy.\n\nWhen a P's ring is full, the G \"overflows\" into the global run queue.",
	"cc": [
		"golang-dev@googlegroups.com"
	],
	"reviewers": [
		"dvyukov@google.com",
		"rsc@golang.org",
		"minux.ma@gmail.com",
		"dave@cheney.net",
		"remyoudompheng@gmail.com",
		"Matthew.Horsnell@gmail.com"
	],
	"messages": [
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Devon,\r\n\r\nThanks for working on this. Have you coordinated with Dmitriy about this? I\r\ndon't know what he plans for future work and want to make sure we don't\r\nstep on him. Separately, I would prefer to wait on this for at least the\r\nrest of the week. There have been vague reports of crashes and such using\r\nthe new scheduler, and I'd like to let things stop changing for a few days\r\nto see if we can stabilize before moving on.\r\n\r\nThanks.\r\nRuss\r\n",
			"disapproval": false,
			"date": "2013-03-04 19:54:43.618930",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/4 Russ Cox <rsc@golang.org>:\r\n> Devon,\r\n>\r\n> Thanks for working on this. Have you coordinated with Dmitriy about this? I\r\n> don't know what he plans for future work and want to make sure we don't step\r\n> on him. Separately, I would prefer to wait on this for at least the rest of\r\n> the week. There have been vague reports of crashes and such using the new\r\n> scheduler, and I'd like to let things stop changing for a few days to see if\r\n> we can stabilize before moving on.\r\n\r\nWe had some discussion in a thread on the ML, he suggested uploading\r\nthe CL. Happy to wait on submitting this; I think it probably doesn't\r\nwork on ARM anyway (but I don't have my ARM boards set up to test\r\nquite yet).\r\n\r\n--dho\r\n\r\n> Thanks.\r\n> Russ\r\n",
			"disapproval": false,
			"date": "2013-03-04 19:57:20.050120",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"devon.odell@gmail.com",
				"dvyukov@google.com",
				"rsc@golang.org",
				"minux.ma@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello dvyukov@google.com, rsc@golang.org, minux.ma@gmail.com, dave@cheney.net (cc: golang-dev@googlegroups.com),\n\nI'd like you to review this change to\nhttps://code.google.com/p/go/",
			"disapproval": false,
			"date": "2013-03-04 18:43:48.606570",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I haven't tested this on ARM yet; I'm not sure if it compiles. This\r\nalgorithm is sensitive to store / load ordering, which means that if\r\nthis causes ARM to fail, we're going to need to implement DSB/DMB\r\ninstructions in 5a. I'm not sure if the LL/SC loops are enough, but I\r\nfigured that work should go in a different CL. (Also, I have no idea\r\nhow to do it having never really messed with the compilers.)\r\n\r\nInteresting benchmarks:\r\n\r\nBenchmarkFields                           30561068     24279386  -20.55%\r\nBenchmarkFieldsFunc                       30054191     24357377  -18.96%\r\nBenchmarkReaderCopyOptimal                    1509         1534   +1.66%\r\nBenchmarkReaderCopyUnoptimal                  7562         5602  -25.92%\r\nBenchmarkReaderCopyNoWriteTo                 10675        11640   +9.04%\r\nBenchmarkWriterCopyOptimal                    9261         4473  -51.70%\r\nBenchmarkWriterCopyUnoptimal                  7318         2757  -62.33%\r\nBenchmarkWriterCopyNoReadFrom                10609        12184  +14.85%\r\nBenchmarkReadString                           5494         6213  +13.09%\r\nBenchmarkIndexByte32                             6            7  +13.89%\r\nBenchmarkIndexByte4K                           238          253   +6.30%\r\nBenchmarkIndexByte4M                        261574       261425   -0.06%\r\nBenchmarkIndexByte64M                      4331658      5021060  +15.92%\r\nBenchmarkIndexBytePortable32                    42           44   +5.19%\r\nBenchmarkIndexBytePortable4K                  2345         2448   +4.39%\r\nBenchmarkIndexBytePortable4M               2416851      2533766   +4.84%\r\nBenchmarkIndexBytePortable64M             38112846     38451022   +0.89%\r\nBenchmarkEqual32                                39           42   +7.91%\r\nBenchmarkEqual4K                              2331         2418   +3.73%\r\nBenchmarkEqual4M                           2586779      2677882   +3.52%\r\nBenchmarkEqual64M                         40851645     41153023   +0.74%\r\nBenchmarkEqualPort32                            46           49   +6.29%\r\nBenchmarkEqualPort4K                          3496         3624   +3.66%\r\nBenchmarkEqualPortable4M                   3776748      3765554   -0.30%\r\nBenchmarkEqualPortable64M                 58643898     60004963   +2.32%\r\nBenchmarkIndex32                               664          685   +3.16%\r\nBenchmarkIndex4K                            101669       105488   +3.76%\r\nBenchmarkIndex4M                         104609738    111066889   +6.17%\r\nBenchmarkIndex64M                       1676273044   1750548375   +4.43%\r\nBenchmarkIndexEasy32                            58           60   +3.09%\r\nBenchmarkIndexEasy4K                           288          292   +1.39%\r\nBenchmarkIndexEasy4M                        254642       282289  +10.86%\r\nBenchmarkIndexEasy64M                      4385937      4525697   +3.19%\r\nBenchmarkCount32                               673          667   -0.89%\r\nBenchmarkCount4K                            103380       103880   +0.48%\r\nBenchmarkCount4M                         106307010    104518944   -1.68%\r\nBenchmarkCount64M                       1702085125   1677917865   -1.42%\r\nBenchmarkCountEasy32                            59           59   +1.01%\r\nBenchmarkCountEasy4K                           289          292   +1.04%\r\nBenchmarkCountEasy4M                        262517       267442   +1.88%\r\nBenchmarkCountEasy64M                      4344423      4299636   -1.03%\r\nBenchmarkTrimSpace                              59           55   -6.61%\r\nBenchmarkSprintfEmpty                           98           99   +1.63%\r\nBenchmarkSprintfString                         284          279   -1.76%\r\nBenchmarkSprintfInt                            226          217   -3.98%\r\nBenchmarkSprintfIntInt                         345          335   -2.90%\r\nBenchmarkSprintfPrefixedInt                    345          356   +3.19%\r\nBenchmarkSprintfFloat                          470          468   -0.43%\r\nBenchmarkManyArgs                             1338         1301   -2.77%\r\nBenchmarkScanInts                           964898       974407   +0.99%\r\nBenchmarkScanRecursiveInt                  1180694      1250752   +5.93%\r\n\r\nBenchmarkTCPOneShot                         121556       118597   -2.43%\r\nBenchmarkTCPOneShotTimeout                  636851       601332   -5.58%\r\nBenchmarkTCPPersistent                       50440        48279   -4.28%\r\nBenchmarkTCPPersistentTimeout                50095        49055   -2.08%\r\n\r\nBenchmarkSelectUncontended                     243          234   -3.70%\r\nBenchmarkSelectContended                       241          236   -2.07%\r\nBenchmarkSelectNonblock                        105          104   -0.95%\r\n\r\nBenchmarkChanUncontended                        64           65   +2.03%\r\nBenchmarkChanContended                          64           64   -0.47%\r\nBenchmarkChanSync                              137          120  -12.41%\r\nBenchmarkChanProdCons0                         140          121  -13.57%\r\nBenchmarkChanProdCons10                         87           83   -5.24%\r\nBenchmarkChanProdCons100                        70           66   -5.55%\r\nBenchmarkChanProdConsWork0                     633          584   -7.74%\r\nBenchmarkChanProdConsWork10                    544          549   +0.92%\r\nBenchmarkChanProdConsWork100                   526          533   +1.33%\r\nBenchmarkChanCreation                          164          172   +4.88%\r\nBenchmarkChanSem                                61           65   +6.01%\r\n\r\nBenchmarkCallClosure                             2            2   +7.24%\r\nBenchmarkCallClosure1                            3            3   +0.32%\r\nBenchmarkCallClosure2                           42           42   +0.70%\r\nBenchmarkCallClosure3                           43           45   +3.90%\r\nBenchmarkCallClosure4                           43           43   +0.23%\r\n\r\nBenchmarkSyscall                                28           27   -2.84%\r\nBenchmarkSyscallWork                           192          187   -2.60%\r\nBenchmarkSyscallExcess                          28           27   -2.47%\r\nBenchmarkSyscallExcessWork                     189          193   +2.12%\r\n\r\nBenchmarkCreateGoroutines                      111           87  -21.08%\r\nBenchmarkCreateGoroutinesParallel              114           90  -20.79%\r\n\r\nBenchmarkUncontendedSemaphore                   25           26   +3.59%\r\nBenchmarkContendedSemaphore                     80           26  -66.50%\r\nBenchmarkMutexUncontended                       17           18   +3.43%\r\nBenchmarkMutex                                  17           18   +0.56%\r\nBenchmarkMutexSlack                             17           17   +0.56%\r\nBenchmarkMutexWork                             176          178   +1.14%\r\nBenchmarkMutexWorkSlack                        178          176   -1.12%\r\nBenchmarkOnce                                    5            5   -2.09%\r\nBenchmarkSemaUncontended                        25           26   +3.17%\r\nBenchmarkSemaSyntNonblock                       25           26   +0.77%\r\nBenchmarkSemaSyntBlock                          25           26   +1.54%\r\nBenchmarkSemaWorkNonblock                      191          192   +0.52%\r\nBenchmarkSemaWorkBlock                         191          192   +0.52%\r\nBenchmarkRWMutexUncontended                     66           69   +4.35%\r\nBenchmarkRWMutexWrite100                        22           22   +1.33%\r\nBenchmarkRWMutexWrite10                         24           24   +0.00%\r\nBenchmarkRWMutexWorkWrite100                   189          186   -1.59%\r\nBenchmarkRWMutexWorkWrite10                    173          177   +2.31%\r\n\r\nBenchmarkWaitGroupUncontended                   23           24   +1.26%\r\nBenchmarkWaitGroupAddDone                       21           21   +1.42%\r\nBenchmarkWaitGroupAddDoneWork                  184          184   +0.00%\r\nBenchmarkWaitGroupWait                           5            5   +0.92%\r\nBenchmarkWaitGroupWaitWork                     170          173   +1.76%\r\n\r\nBenchmarkAfterFunc                             428          362  -15.42%\r\nBenchmarkAfter                                 829          607  -26.78%\r\nBenchmarkStop                                  358          280  -21.79%\r\nBenchmarkTicker                              17123        14846  -13.30%\r\nBenchmarkNow                                    14           11  -19.31%\r\nBenchmarkNowUnixNano                            12           11   -5.56%\r\nBenchmarkFormat                                904          617  -31.75%\r\nBenchmarkFormatNow                             685          584  -14.74%\r\nBenchmarkParse                                 486          426  -12.35%\r\nBenchmarkHour                                   19           17  -10.88%\r\nBenchmarkSecond                                 16           15   -2.48%\r\nBenchmarkYear                                   29           30   +2.04%\r\nBenchmarkDay                                    37           40   +6.08%\r\n\r\nDevons-MacBook-Pro:shootout dho$ cat thread-ring-old.txt\r\n        3.02 real         3.01 user         0.00 sys\r\n       10.21 real        11.51 user         4.07 sys\r\n        6.73 real         7.91 user         3.08 sys\r\n        6.11 real         7.27 user         2.74 sys\r\nDevons-MacBook-Pro:shootout dho$ cat thread-ring-new.txt\r\n        2.67 real         2.67 user         0.00 sys\r\n        5.87 real         6.30 user         2.54 sys\r\n        4.66 real         4.88 user         2.17 sys\r\n        4.42 real         4.81 user         1.98 sys\r\n",
			"disapproval": false,
			"date": "2013-03-04 18:52:07.890940",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/4 Devon H. O'Dell <devon.odell@gmail.com>:\r\n> BenchmarkReaderCopyOptimal                    1509         1534   +1.66%\r\n> BenchmarkReaderCopyUnoptimal                  7562         5602  -25.92%\r\n> BenchmarkReaderCopyNoWriteTo                 10675        11640   +9.04%\r\n> BenchmarkWriterCopyOptimal                    9261         4473  -51.70%\r\n> BenchmarkWriterCopyUnoptimal                  7318         2757  -62.33%\r\n> BenchmarkWriterCopyNoReadFrom                10609        12184  +14.85%\r\n\r\nWhy are there differences here? Is it because of a stack split?\r\n\r\nR\u00e9my.\r\n",
			"disapproval": false,
			"date": "2013-03-04 18:55:46.654370",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/4 R\u00e9my Oudompheng <remyoudompheng@gmail.com>:\r\n> 2013/3/4 Devon H. O'Dell <devon.odell@gmail.com>:\r\n>> BenchmarkReaderCopyOptimal                    1509         1534   +1.66%\r\n>> BenchmarkReaderCopyUnoptimal                  7562         5602  -25.92%\r\n>> BenchmarkReaderCopyNoWriteTo                 10675        11640   +9.04%\r\n>> BenchmarkWriterCopyOptimal                    9261         4473  -51.70%\r\n>> BenchmarkWriterCopyUnoptimal                  7318         2757  -62.33%\r\n>> BenchmarkWriterCopyNoReadFrom                10609        12184  +14.85%\r\n>\r\n> Why are there differences here? Is it because of a stack split?\r\n>\r\n\r\nGC accounts for 75% of the profile, and it runs thousands of times\r\nduring the benchmark, I'm not sure anything can be said reliably.\r\n\r\nR\u00e9my.\r\n",
			"disapproval": false,
			"date": "2013-03-04 19:20:56.904760",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/4 R\u00e9my Oudompheng <remyoudompheng@gmail.com>:\r\n> 2013/3/4 R\u00e9my Oudompheng <remyoudompheng@gmail.com>:\r\n>> 2013/3/4 Devon H. O'Dell <devon.odell@gmail.com>:\r\n>>> BenchmarkReaderCopyOptimal                    1509         1534   +1.66%\r\n>>> BenchmarkReaderCopyUnoptimal                  7562         5602  -25.92%\r\n>>> BenchmarkReaderCopyNoWriteTo                 10675        11640   +9.04%\r\n>>> BenchmarkWriterCopyOptimal                    9261         4473  -51.70%\r\n>>> BenchmarkWriterCopyUnoptimal                  7318         2757  -62.33%\r\n>>> BenchmarkWriterCopyNoReadFrom                10609        12184  +14.85%\r\n>>\r\n>> Why are there differences here? Is it because of a stack split?\r\n>>\r\n>\r\n> GC accounts for 75% of the profile, and it runs thousands of times\r\n> during the benchmark, I'm not sure anything can be said reliably.\r\n\r\nOk, that's fair. I was curious about this myself. (But I'm still\r\nramping up on figuring out how to profile Go programs; apparently it's\r\nunreliable on mac, or so says #go-nuts.)\r\n\r\nI'd hope this isn't also true of the select/chan/goroutine benchmarks.\r\n\r\n--dho\r\n\r\n> R\u00e9my.\r\n",
			"disapproval": false,
			"date": "2013-03-04 19:24:52.540770",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/4 Devon H. O'Dell <devon.odell@gmail.com>:\r\n> 2013/3/4 R\u00e9my Oudompheng <remyoudompheng@gmail.com>:\r\n>> 2013/3/4 R\u00e9my Oudompheng <remyoudompheng@gmail.com>:\r\n>>> 2013/3/4 Devon H. O'Dell <devon.odell@gmail.com>:\r\n>>>> BenchmarkReaderCopyOptimal                    1509         1534   +1.66%\r\n>>>> BenchmarkReaderCopyUnoptimal                  7562         5602  -25.92%\r\n>>>> BenchmarkReaderCopyNoWriteTo                 10675        11640   +9.04%\r\n>>>> BenchmarkWriterCopyOptimal                    9261         4473  -51.70%\r\n>>>> BenchmarkWriterCopyUnoptimal                  7318         2757  -62.33%\r\n>>>> BenchmarkWriterCopyNoReadFrom                10609        12184  +14.85%\r\n>>>\r\n>>> Why are there differences here? Is it because of a stack split?\r\n>>>\r\n>>\r\n>> GC accounts for 75% of the profile, and it runs thousands of times\r\n>> during the benchmark, I'm not sure anything can be said reliably.\r\n>\r\n> Ok, that's fair. I was curious about this myself. (But I'm still\r\n> ramping up on figuring out how to profile Go programs; apparently it's\r\n> unreliable on mac, or so says #go-nuts.)\r\n>\r\n> I'd hope this isn't also true of the select/chan/goroutine benchmarks.\r\n\r\nThe improvement seems real in the threadring benchmark.\r\n\r\nBefore:\r\nTotal: 657 samples\r\n     184  28.0%  28.0%      184  28.0% runtime.xchg\r\n      87  13.2%  41.2%       87  13.2% runtime.futex\r\n      73  11.1%  52.4%      306  46.6% runtime.chansend\r\n      42   6.4%  58.8%      472  71.8% testa.f\r\n      37   5.6%  64.4%       37   5.6% dequeue\r\n      35   5.3%  69.7%      118  18.0% runtime.chanrecv\r\n      35   5.3%  75.0%      103  15.7% runtime.unlock\r\n      23   3.5%  78.5%      124  18.9% schedule\r\n      22   3.3%  81.9%      149  22.7% runtime.lock\r\n      19   2.9%  84.8%       43   6.5% runqget\r\n\r\nAfter:\r\nTotal: 597 samples\r\n     116  19.4%  19.4%      116  19.4% runtime.xchg\r\n      84  14.1%  33.5%       84  14.1% runtime.futex\r\n      56   9.4%  42.9%      427  71.5% testa.f\r\n      54   9.0%  51.9%      263  44.1% runtime.chansend\r\n      36   6.0%  58.0%       95  15.9% runtime.chanrecv\r\n      30   5.0%  63.0%       30   5.0% dequeue\r\n      29   4.9%  67.8%      104  17.4% runtime.lock\r\n      27   4.5%  72.4%       27   4.5% runtime.atomicload\r\n      26   4.4%  76.7%      113  18.9% schedule\r\n      21   3.5%  80.2%       43   7.2% runqget\r\n\r\npackage main\r\n\r\nimport (\r\n\t\"sync\"\r\n\t\"testing\"\r\n)\r\n\r\nconst Nthread = 503\r\n\r\nfunc f(i int, in <-chan int, out chan<- int, wg *sync.WaitGroup) {\r\n\tfor {\r\n\t\tn := <-in\r\n\t\tif n == 0 {\r\n\t\t\twg.Done()\r\n\t\t\tout <- 0\r\n\t\t}\r\n\t\tout <- n - 1\r\n\t}\r\n}\r\n\r\nfunc BenchmarkThreadRing(b *testing.B) {\r\n\tone := make(chan int) // will be input to thread 1\r\n\tvar in, out chan int = nil, one\r\n\twg := new(sync.WaitGroup)\r\n\twg.Add(Nthread)\r\n\tfor i := 1; i <= Nthread-1; i++ {\r\n\t\tin, out = out, make(chan int)\r\n\t\tgo f(i, in, out, wg)\r\n\t}\r\n\tgo f(Nthread, out, one, wg)\r\n\tone <- b.N\r\n\twg.Wait()\r\n}\r\n",
			"disapproval": false,
			"date": "2013-03-04 19:39:11.374860",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"devon.odell@gmail.com",
				"dvyukov@google.com",
				"rsc@golang.org",
				"minux.ma@gmail.com",
				"dave@cheney.net",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c\nFile src/pkg/runtime/proc.c (right):\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode279\nsrc/pkg/runtime/proc.c:279: if (runqput(m->p, gp) == false) {\nPerhaps combine it in a separate function, because it's copied several times.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode281\nsrc/pkg/runtime/proc.c:281: globrunqput(gp);\nit important to transfer a batch of G's to globrunq (half?)\nconsider that a goroutine spawns lots of goroutines in a loop, you do not want to hit the slowpath every time\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode355\nsrc/pkg/runtime/proc.c:355: runtime\u00b7fastatomicstore((uint32*)&runtime\u00b7gcwaiting, 1);\nThis needs full memory barrier between store to gcwaiting and load of p->status, otherwise it can deadlock with entersyscall (both won't notice the other).\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1014\nsrc/pkg/runtime/proc.c:1014: gp = runqget(p);\n\"steal half\" is required here.\nconsider that a goroutine spawns lots of other goroutines in a loop, then other worker threads starts stealing 1 goroutine from slowpath each time, this will lead to unnecessary contention and slowdown.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1214\nsrc/pkg/runtime/proc.c:1214: runtime\u00b7fastatomicstore(&m->p->status, Psyscall);\nfull memory barrier is required, otherwise it will deadlock with stoptheworld.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1760\nsrc/pkg/runtime/proc.c:1760: if(old < 0 || old > MaxGomaxprocs || new <= 0 || new > MaxGomaxprocs)\nsuch edits better go in a separate patch\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2042\nsrc/pkg/runtime/proc.c:2042: if(runqput(p, gp1) == false) {\nsteal at most runqsize (128), then runqput() will always succeed\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2087\nsrc/pkg/runtime/proc.c:2087: if((delta & mask) == (start & mask))\nIs it intended that you do not full the last slot?\nIf so, it can be:\nif((delta^start)&mask))\nthe compiler is not particularly good at code optimization.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2093\nsrc/pkg/runtime/proc.c:2093: runtime\u00b7fastatomicstore(&p->r_tail, delta);\natomicstorerelease should contain the necessary fence\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2094\nsrc/pkg/runtime/proc.c:2094: \nplease drop at least some of the empty lines\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2107\nsrc/pkg/runtime/proc.c:2107: start = runtime\u00b7atomicload(&p->r_head);\nplease use consistent maning: head/head instead of head/start (tail/end)\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2109\nsrc/pkg/runtime/proc.c:2109: /* TODO: load fence */\natomicload contains the fence\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2114\nsrc/pkg/runtime/proc.c:2114: /* TODO: load fence */\nwhy is it needed?\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\nsrc/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\nI think you can implement steal in a similar way, just copying a batch of elements here and incrementing head by N instead on 1.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\nsrc/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\nI think you can implement steal() in a similar way, just copying a batch of elements here and incrementing head by N instead of 1.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2118\nsrc/pkg/runtime/proc.c:2118: /* TODO: full memory fence */\nwhy is it needed?\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2133\nsrc/pkg/runtime/proc.c:2133: p.r_size = 8192;\nplease test overflow as well\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h\nFile src/pkg/runtime/runtime.h (right):\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode339\nsrc/pkg/runtime/runtime.h:339: G**\tring;\nI think size 128 should be enough.\nEmbed it into P directly:\nenum { RunqSize = 128 };\nG* ring[RunqSize];\nThen you don't need mask.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode340\nsrc/pkg/runtime/runtime.h:340: uint32\tr_head;\nRename, the codebase does not use underscores.\nPlease refrain from unnecessary renaming, uint32 runqhead is fine. This will eliminate lots of edits in proc.c\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode690\nsrc/pkg/runtime/runtime.h:690: bool\truntime\u00b7casvalue(uint32*, uint32, uint32, uint32*);\nChange cas(uint32*, uint32, uint32) to cas(uint32*, uint32*, uint32) similar to cas64. Then you don't need the separate function.\nThis should go in a separate patch.\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode697\nsrc/pkg/runtime/runtime.h:697: void\truntime\u00b7fastatomicstore(uint32 volatile*, uint32);\nrename to atomicstorerelease\n\nhttps://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode738\nsrc/pkg/runtime/runtime.h:738: void\truntime\u00b7setmg(M*, G*);\nSuch changes better go in a separate patch.",
			"disapproval": false,
			"date": "2013-03-08 18:23:27.464630",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hi,\r\n\r\nHaven't had a lot of time to fix this recently but I wanted to address\r\nsome of the comments.\r\n\r\n2013/3/8  <dvyukov@google.com>:\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c\r\n> File src/pkg/runtime/proc.c (right):\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode279\r\n> src/pkg/runtime/proc.c:279: if (runqput(m->p, gp) == false) {\r\n> Perhaps combine it in a separate function, because it's copied several\r\n> times.\r\n\r\nThat will get inlined, yes? With some of the other comments you made,\r\nthe number of times this is copied will probably decrease (as a result\r\nof implementing the work stealing).\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode281\r\n> src/pkg/runtime/proc.c:281: globrunqput(gp);\r\n> it important to transfer a batch of G's to globrunq (half?)\r\n> consider that a goroutine spawns lots of goroutines in a loop, you do\r\n> not want to hit the slowpath every time\r\n\r\nThat's fair -- didn't want to make this a bigger change than I needed\r\nto. I'll look at doing this.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode355\r\n> src/pkg/runtime/proc.c:355:\r\n> runtime\u00b7fastatomicstore((uint32*)&runtime\u00b7gcwaiting, 1);\r\n> This needs full memory barrier between store to gcwaiting and load of\r\n> p->status, otherwise it can deadlock with entersyscall (both won't\r\n> notice the other).\r\n\r\nGood point. I'm going to remove the other places where I changed this\r\nthat aren't specifically related to the run queue. I didn't look at\r\nindepended load / store dependencies, and that's clearly showing.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1014\r\n> src/pkg/runtime/proc.c:1014: gp = runqget(p);\r\n> \"steal half\" is required here.\r\n> consider that a goroutine spawns lots of other goroutines in a loop,\r\n> then other worker threads starts stealing 1 goroutine from slowpath each\r\n> time, this will lead to unnecessary contention and slowdown.\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1214\r\n> src/pkg/runtime/proc.c:1214: runtime\u00b7fastatomicstore(&m->p->status,\r\n> Psyscall);\r\n> full memory barrier is required, otherwise it will deadlock with\r\n> stoptheworld.\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode1760\r\n> src/pkg/runtime/proc.c:1760: if(old < 0 || old > MaxGomaxprocs || new <=\r\n> 0 || new > MaxGomaxprocs)\r\n> such edits better go in a separate patch\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2042\r\n> src/pkg/runtime/proc.c:2042: if(runqput(p, gp1) == false) {\r\n> steal at most runqsize (128), then runqput() will always succeed\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2087\r\n> src/pkg/runtime/proc.c:2087: if((delta & mask) == (start & mask))\r\n> Is it intended that you do not full the last slot?\r\n> If so, it can be:\r\n> if((delta^start)&mask))\r\n> the compiler is not particularly good at code optimization.\r\n\r\nThis check won't work. We can't enqueue a new value into the ring if\r\nthat would overflow the ring. So, if delta == start, we don't insert.\r\nIf we have a ring of size 4, the tail is at 0x3 and the head is at\r\n0x0, this will end up being if(0&mask), which is of course always\r\nfalse.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2093\r\n> src/pkg/runtime/proc.c:2093: runtime\u00b7fastatomicstore(&p->r_tail, delta);\r\n> atomicstorerelease should contain the necessary fence\r\n\r\nThe store fence is required to serialize the update of the tail with\r\nrespect to putting the entry in the ring, so it's not really a\r\nquestion of whether this interface provides the fence. It's to make\r\nsure that all other consumers do not read that the tail is updated\r\nwithout being guaranteed to be able to read the entry at the tail.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2094\r\n> src/pkg/runtime/proc.c:2094:\r\n> please drop at least some of the empty lines\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2107\r\n> src/pkg/runtime/proc.c:2107: start = runtime\u00b7atomicload(&p->r_head);\r\n> please use consistent maning: head/head instead of head/start (tail/end)\r\n\r\nI will change these for consistency / to reduce diff size as suggested later.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2109\r\n> src/pkg/runtime/proc.c:2109: /* TODO: load fence */\r\n> atomicload contains the fence\r\n\r\nThis is to guarantee consistency of our view of the snapshot of the head.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2114\r\n> src/pkg/runtime/proc.c:2114: /* TODO: load fence */\r\n> why is it needed?\r\n\r\nSame reason, guarantee we're looking at the proper state of the head\r\nwhen we do the assignment from the ring.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\r\n> src/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\r\n> I think you can implement steal in a similar way, just copying a batch\r\n> of elements here and incrementing head by N instead on 1.\r\n\r\nIt would be possible to do this with a memcpy indeed, but you have to\r\ndo the copy every iteration of the loop because head may have changed.\r\nAnother way I was thinking of doing it was just to \"steal\" the blocks\r\nand do the copies once that was successful -- but the problem is that\r\nanother producer might invalidate the consistency of the ring by the\r\ntime the copy started. I'll do the memcpy approach for now.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\r\n> src/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\r\n> I think you can implement steal() in a similar way, just copying a batch\r\n> of elements here and incrementing head by N instead of 1.\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2118\r\n> src/pkg/runtime/proc.c:2118: /* TODO: full memory fence */\r\n> why is it needed?\r\n\r\nTo serialize loading with respect to updating the head poitner.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2133\r\n> src/pkg/runtime/proc.c:2133: p.r_size = 8192;\r\n> please test overflow as well\r\n\r\nGood call. Will do.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h\r\n> File src/pkg/runtime/runtime.h (right):\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode339\r\n> src/pkg/runtime/runtime.h:339: G**      ring;\r\n> I think size 128 should be enough.\r\n> Embed it into P directly:\r\n> enum { RunqSize = 128 };\r\n> G* ring[RunqSize];\r\n> Then you don't need mask.\r\n\r\nAlso good call.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode340\r\n> src/pkg/runtime/runtime.h:340: uint32   r_head;\r\n> Rename, the codebase does not use underscores.\r\n> Please refrain from unnecessary renaming, uint32 runqhead is fine. This\r\n> will eliminate lots of edits in proc.c\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode690\r\n> src/pkg/runtime/runtime.h:690: bool     runtime\u00b7casvalue(uint32*, uint32,\r\n> uint32, uint32*);\r\n> Change cas(uint32*, uint32, uint32) to cas(uint32*, uint32*, uint32)\r\n> similar to cas64. Then you don't need the separate function.\r\n> This should go in a separate patch.\r\n\r\nThen we pay the cost for assigning to the old value everywhere, even\r\nwhen we don't need it. I think this just adds overhead.\r\n\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode697\r\n> src/pkg/runtime/runtime.h:697: void     runtime\u00b7fastatomicstore(uint32\r\n> volatile*, uint32);\r\n> rename to atomicstorerelease\r\n>\r\n> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode738\r\n> src/pkg/runtime/runtime.h:738: void     runtime\u00b7setmg(M*, G*);\r\n> Such changes better go in a separate patch.\r\n>\r\n> https://codereview.appspot.com/7455049/\r\n",
			"disapproval": false,
			"date": "2013-03-12 15:38:43.392280",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "The C compiler does not inline.\r\n",
			"disapproval": false,
			"date": "2013-03-12 15:45:10.107260",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/12 Russ Cox <rsc@golang.org>:\r\n> The C compiler does not inline.\r\n\r\nMaybe we should revisit this after Go 1.1.\r\n\r\nI need help implementing support for the DMB instruction on ARM. I\r\ndon't understand the assembler and linker code enough to add the\r\ninstruction and this won't work on ARM without that. Additionally,\r\nwe'd need an interface for generating memory barriers. If the C\r\ncompiler doesn't inline, that's going to be a ton of overhead just to\r\ngenerate sfence/lfence/dmb.\r\n\r\nThat in mind, I'm happy to work hard to get this going for the 1.1\r\nrelease, but I think it's maybe going to take too much time from other\r\nthings that really need to go in.\r\n\r\n--dho\r\n",
			"disapproval": false,
			"date": "2013-03-12 15:50:25.862450",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell <devon.odell@gmail.com>wrote:\r\n\r\n> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n> > The C compiler does not inline.\r\n>\r\n> Maybe we should revisit this after Go 1.1.\r\n>\r\n\r\n> I need help implementing support for the DMB instruction on ARM. I\r\n> don't understand the assembler and linker code enough to add the\r\n> instruction and this won't work on ARM without that. Additionally,\r\n> we'd need an interface for generating memory barriers. If the C\r\n> compiler doesn't inline, that's going to be a ton of overhead just to\r\n> generate sfence/lfence/dmb.\r\n>\r\n\r\nI am happy to add intrinsics if you demonstrate that the performance win is\r\nenough. We did this already with prefetch.\r\n\r\nI very much doubt the C compiler will ever inline. For the tiny amount of C\r\nwe have, it's just not worth the effort. It certainly can't inline calls to\r\nassembly functions that it can't see.\r\n\r\nRuss\r\n",
			"disapproval": false,
			"date": "2013-03-12 15:56:01.413670",
			"approval": false
		},
		{
			"sender": "devon.odell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "2013/3/12 Russ Cox <rsc@golang.org>:\r\n> On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell <devon.odell@gmail.com>\r\n> wrote:\r\n>>\r\n>> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n>> > The C compiler does not inline.\r\n>>\r\n>> Maybe we should revisit this after Go 1.1.\r\n>>\r\n>>\r\n>> I need help implementing support for the DMB instruction on ARM. I\r\n>> don't understand the assembler and linker code enough to add the\r\n>> instruction and this won't work on ARM without that. Additionally,\r\n>> we'd need an interface for generating memory barriers. If the C\r\n>> compiler doesn't inline, that's going to be a ton of overhead just to\r\n>> generate sfence/lfence/dmb.\r\n>\r\n>\r\n> I am happy to add intrinsics if you demonstrate that the performance win is\r\n> enough. We did this already with prefetch.\r\n\r\nWhat benchmarks do you want me to run? I'll only be able to run them\r\nreliably on x86 and AMD64 until there's support for DMB. This\r\ninstruction is required for consistency using the lock-free data\r\nstructure to guarantee that stores / loads are observed by other\r\nthreads; it's not really for performance. I guess in the meantime I\r\ncould make an ASM stub using .BYTE?\r\n\r\n> I very much doubt the C compiler will ever inline. For the tiny amount of C\r\n> we have, it's just not worth the effort. It certainly can't inline calls to\r\n> assembly functions that it can't see.\r\n\r\nThat's fair.\r\n\r\n> Russ\r\n\r\n--dho\r\n",
			"disapproval": false,
			"date": "2013-03-12 16:07:28.090300",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Tue, Mar 12, 2013 at 7:38 PM, Devon H. O'Dell <devon.odell@gmail.com> wrote:\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode279\r\n>> src/pkg/runtime/proc.c:279: if (runqput(m->p, gp) == false) {\r\n>> Perhaps combine it in a separate function, because it's copied several\r\n>> times.\r\n>\r\n> That will get inlined, yes?\r\n\r\n\r\nNo, it won't.\r\n\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2087\r\n>> src/pkg/runtime/proc.c:2087: if((delta & mask) == (start & mask))\r\n>> Is it intended that you do not full the last slot?\r\n>> If so, it can be:\r\n>> if((delta^start)&mask))\r\n>> the compiler is not particularly good at code optimization.\r\n>\r\n> This check won't work. We can't enqueue a new value into the ring if\r\n> that would overflow the ring. So, if delta == start, we don't insert.\r\n> If we have a ring of size 4, the tail is at 0x3 and the head is at\r\n> 0x0, this will end up being if(0&mask), which is of course always\r\n> false.\r\n\r\nI meant ((delta^start)&mask) == 0\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2093\r\n>> src/pkg/runtime/proc.c:2093: runtime\u00b7fastatomicstore(&p->r_tail, delta);\r\n>> atomicstorerelease should contain the necessary fence\r\n>\r\n> The store fence is required to serialize the update of the tail with\r\n> respect to putting the entry in the ring, so it's not really a\r\n> question of whether this interface provides the fence. It's to make\r\n> sure that all other consumers do not read that the tail is updated\r\n> without being guaranteed to be able to read the entry at the tail.\r\n\r\n\r\natomicstorerelease should contain the necessary fence, the TODO is not necessary\r\n\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2109\r\n>> src/pkg/runtime/proc.c:2109: /* TODO: load fence */\r\n>> atomicload contains the fence\r\n>\r\n> This is to guarantee consistency of our view of the snapshot of the head.\r\n\r\nYes, I understand, but please remove the TODO, because it's not\r\nactually the TODO, the fence is already there.\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2114\r\n>> src/pkg/runtime/proc.c:2114: /* TODO: load fence */\r\n>> why is it needed?\r\n>\r\n> Same reason, guarantee we're looking at the proper state of the head\r\n> when we do the assignment from the ring.\r\n\r\n\r\nThe necessary fence is in atomicload/cas.\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\r\n>> src/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\r\n>> I think you can implement steal in a similar way, just copying a batch\r\n>> of elements here and incrementing head by N instead on 1.\r\n>\r\n> It would be possible to do this with a memcpy indeed, but you have to\r\n> do the copy every iteration of the loop\r\n\r\nI think it is fine\r\n\r\n> because head may have changed.\r\n> Another way I was thinking of doing it was just to \"steal\" the blocks\r\n> and do the copies once that was successful -- but the problem is that\r\n> another producer might invalidate the consistency of the ring by the\r\n> time the copy started. I'll do the memcpy approach for now.\r\n>\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2116\r\n>> src/pkg/runtime/proc.c:2116: gp = p->ring[start & mask];\r\n>> I think you can implement steal() in a similar way, just copying a batch\r\n>> of elements here and incrementing head by N instead of 1.\r\n>>\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/proc.c#newcode2118\r\n>> src/pkg/runtime/proc.c:2118: /* TODO: full memory fence */\r\n>> why is it needed?\r\n>\r\n> To serialize loading with respect to updating the head poitner.\r\n\r\ncas contains the necessary fence, these are *not* relaxed atomic\r\n\r\n\r\n\r\n>> https://codereview.appspot.com/7455049/diff/4001/src/pkg/runtime/runtime.h#newcode690\r\n>> src/pkg/runtime/runtime.h:690: bool     runtime\u00b7casvalue(uint32*, uint32,\r\n>> uint32, uint32*);\r\n>> Change cas(uint32*, uint32, uint32) to cas(uint32*, uint32*, uint32)\r\n>> similar to cas64. Then you don't need the separate function.\r\n>> This should go in a separate patch.\r\n>\r\n> Then we pay the cost for assigning to the old value everywhere, even\r\n> when we don't need it. I think this just adds overhead.\r\n\r\n\r\nLocal assignment is not a great cost. The cc compiler makes\r\nunnecessary assignments everywhere. And it's needed in mutexes and\r\nwill be needed in chans. Most other places are not performance\r\ncritical.\r\n",
			"disapproval": false,
			"date": "2013-03-12 16:18:01.864770",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Tue, Mar 12, 2013 at 8:07 PM, Devon H. O'Dell <devon.odell@gmail.com> wrote:\r\n> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n>> On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell <devon.odell@gmail.com>\r\n>> wrote:\r\n>>>\r\n>>> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n>>> > The C compiler does not inline.\r\n>>>\r\n>>> Maybe we should revisit this after Go 1.1.\r\n>>>\r\n>>>\r\n>>> I need help implementing support for the DMB instruction on ARM. I\r\n>>> don't understand the assembler and linker code enough to add the\r\n>>> instruction and this won't work on ARM without that. Additionally,\r\n>>> we'd need an interface for generating memory barriers. If the C\r\n>>> compiler doesn't inline, that's going to be a ton of overhead just to\r\n>>> generate sfence/lfence/dmb.\r\n>>\r\n>>\r\n>> I am happy to add intrinsics if you demonstrate that the performance win is\r\n>> enough. We did this already with prefetch.\r\n>\r\n> What benchmarks do you want me to run? I'll only be able to run them\r\n> reliably on x86 and AMD64 until there's support for DMB. This\r\n> instruction is required for consistency using the lock-free data\r\n> structure to guarantee that stores / loads are observed by other\r\n> threads; it's not really for performance. I guess in the meantime I\r\n> could make an ASM stub using .BYTE?\r\n\r\nDMB should not be a separate function, it should be combined with\r\natomicload/store/cas/etc. So there will be no additional cost for\r\nthese.\r\n\r\nFor ARM you can just use existing atomic functions, they meant to\r\ncontain all the necessary fences. You can think of them as C\r\natomic_foo(memory_order_seq_cst).\r\n",
			"disapproval": false,
			"date": "2013-03-12 16:21:32.958220",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Tue, Mar 12, 2013 at 12:07 PM, Devon H. O'Dell <devon.odell@gmail.com>wrote:\r\n\r\n> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n> > On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell <devon.odell@gmail.com\r\n> >\r\n> > wrote:\r\n> >>\r\n> >> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n> >> > The C compiler does not inline.\r\n> >>\r\n> >> Maybe we should revisit this after Go 1.1.\r\n> >>\r\n> >>\r\n> >> I need help implementing support for the DMB instruction on ARM. I\r\n> >> don't understand the assembler and linker code enough to add the\r\n> >> instruction and this won't work on ARM without that. Additionally,\r\n> >> we'd need an interface for generating memory barriers. If the C\r\n> >> compiler doesn't inline, that's going to be a ton of overhead just to\r\n> >> generate sfence/lfence/dmb.\r\n> >\r\n> >\r\n> > I am happy to add intrinsics if you demonstrate that the performance win\r\n> is\r\n> > enough. We did this already with prefetch.\r\n>\r\n> What benchmarks do you want me to run? I'll only be able to run them\r\n> reliably on x86 and AMD64 until there's support for DMB. This\r\n> instruction is required for consistency using the lock-free data\r\n> structure to guarantee that stores / loads are observed by other\r\n> threads; it's not really for performance. I guess in the meantime I\r\n> could make an ASM stub using .BYTE?\r\n>\r\n\r\nI'd like to see a version that calls into assembly (you want WORD $x, not\r\nBYTE, and no dot), compared with a version that doesn't. In the case of\r\nprefetch, the difference was significant enough to add to the compiler.\r\n\r\nTo compare with the version that doesn't call into assembly, you can patch\r\nin CL 7756043, with two caveats:\r\n1. It's not done well, and it would need redoing if we keep it.\r\n2. The linker emits DSB as 0xFFFFFFFF, which I assume is not the actual\r\nencoding. You'll need to tweak that before using.\r\n\r\nRuss\r\n",
			"disapproval": false,
			"date": "2013-03-12 16:26:09.213540",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Tue, Mar 12, 2013 at 8:26 PM, Russ Cox <rsc@golang.org> wrote:\r\n> On Tue, Mar 12, 2013 at 12:07 PM, Devon H. O'Dell <devon.odell@gmail.com>\r\n> wrote:\r\n>>\r\n>> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n>> > On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell\r\n>> > <devon.odell@gmail.com>\r\n>> > wrote:\r\n>> >>\r\n>> >> 2013/3/12 Russ Cox <rsc@golang.org>:\r\n>> >> > The C compiler does not inline.\r\n>> >>\r\n>> >> Maybe we should revisit this after Go 1.1.\r\n>> >>\r\n>> >>\r\n>> >> I need help implementing support for the DMB instruction on ARM. I\r\n>> >> don't understand the assembler and linker code enough to add the\r\n>> >> instruction and this won't work on ARM without that. Additionally,\r\n>> >> we'd need an interface for generating memory barriers. If the C\r\n>> >> compiler doesn't inline, that's going to be a ton of overhead just to\r\n>> >> generate sfence/lfence/dmb.\r\n>> >\r\n>> >\r\n>> > I am happy to add intrinsics if you demonstrate that the performance win\r\n>> > is\r\n>> > enough. We did this already with prefetch.\r\n>>\r\n>> What benchmarks do you want me to run? I'll only be able to run them\r\n>> reliably on x86 and AMD64 until there's support for DMB. This\r\n>> instruction is required for consistency using the lock-free data\r\n>> structure to guarantee that stores / loads are observed by other\r\n>> threads; it's not really for performance. I guess in the meantime I\r\n>> could make an ASM stub using .BYTE?\r\n>\r\n>\r\n> I'd like to see a version that calls into assembly (you want WORD $x, not\r\n> BYTE, and no dot), compared with a version that doesn't. In the case of\r\n> prefetch, the difference was significant enough to add to the compiler.\r\n>\r\n> To compare with the version that doesn't call into assembly, you can patch\r\n> in CL 7756043, with two caveats:\r\n> 1. It's not done well, and it would need redoing if we keep it.\r\n> 2. The linker emits DSB as 0xFFFFFFFF, which I assume is not the actual\r\n> encoding. You'll need to tweak that before using.\r\n\r\n\r\nWe do not want stand-alone memory fences, the atomic operations we\r\nhave include the memory fences. We can make them finer-grained if\r\nnecessary (e.g. load-acquire, store-release, cas-release, etc).\r\nWhile the atomic operations are in assembly, intrinsic for DMB makes no sense.\r\nIf anything, we need ATOMIC_LOAD/ATOMIC_STORE/ETC intrinsics.\r\n",
			"disapproval": false,
			"date": "2013-03-12 16:37:36.967860",
			"approval": false
		},
		{
			"sender": "matthew.horsnell@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Late to the party, but keen to test this change list. I am trying to use \r\nthe DSB primitive from inside a linked assembly routine. Is DSB expected to \r\nwork from assembly? I'm currently getting the following errors:\r\n\r\ntest_arm.s:19 syntax error, last name: DSB\r\n\r\nOn Tuesday, 12 March 2013 16:26:07 UTC, rsc wrote:\r\n>\r\n> On Tue, Mar 12, 2013 at 12:07 PM, Devon H. O'Dell <devon...@gmail.com<javascript:>\r\n> > wrote:\r\n>\r\n>> 2013/3/12 Russ Cox <r...@golang.org <javascript:>>:\r\n>> > On Tue, Mar 12, 2013 at 11:50 AM, Devon H. O'Dell <devon...@gmail.com<javascript:>\r\n>> >\r\n>> > wrote:\r\n>> >>\r\n>> >> 2013/3/12 Russ Cox <r...@golang.org <javascript:>>:\r\n>> >> > The C compiler does not inline.\r\n>> >>\r\n>> >> Maybe we should revisit this after Go 1.1.\r\n>> >>\r\n>> >>\r\n>> >> I need help implementing support for the DMB instruction on ARM. I\r\n>> >> don't understand the assembler and linker code enough to add the\r\n>> >> instruction and this won't work on ARM without that. Additionally,\r\n>> >> we'd need an interface for generating memory barriers. If the C\r\n>> >> compiler doesn't inline, that's going to be a ton of overhead just to\r\n>> >> generate sfence/lfence/dmb.\r\n>> >\r\n>> >\r\n>> > I am happy to add intrinsics if you demonstrate that the performance \r\n>> win is\r\n>> > enough. We did this already with prefetch.\r\n>>\r\n>> What benchmarks do you want me to run? I'll only be able to run them\r\n>> reliably on x86 and AMD64 until there's support for DMB. This\r\n>> instruction is required for consistency using the lock-free data\r\n>> structure to guarantee that stores / loads are observed by other\r\n>> threads; it's not really for performance. I guess in the meantime I\r\n>> could make an ASM stub using .BYTE?\r\n>>\r\n>\r\n> I'd like to see a version that calls into assembly (you want WORD $x, not \r\n> BYTE, and no dot), compared with a version that doesn't. In the case of \r\n> prefetch, the difference was significant enough to add to the compiler. \r\n>\r\n> To compare with the version that doesn't call into assembly, you can patch \r\n> in CL 7756043, with two caveats:\r\n> 1. It's not done well, and it would need redoing if we keep it.\r\n> 2. The linker emits DSB as 0xFFFFFFFF, which I assume is not the actual \r\n> encoding. You'll need to tweak that before using.\r\n>\r\n> Russ\r\n>\r\n",
			"disapproval": false,
			"date": "2013-03-13 21:55:52.356380",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "No, it doesn't. You can use WORD $0x12345678 with the constant corrected.\r\n\r\nRuss\r\n",
			"disapproval": false,
			"date": "2013-03-13 22:00:50.574650",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I'd like to leave this until after Go 1.1.\r\n",
			"disapproval": false,
			"date": "2013-03-19 18:38:50.527940",
			"approval": false
		}
	],
	"owner_email": "devon.odell@gmail.com",
	"private": false,
	"base_url": "",
	"owner": "dho",
	"subject": "code review 7455049: runtime: use lock-free ring for work scheduling",
	"created": "2013-03-04 18:42:30.428900",
	"patchsets": [
		1,
		2001,
		4001
	],
	"modified": "2013-03-19 18:38:50.527940",
	"closed": false,
	"issue": 7455049
}