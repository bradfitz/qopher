{
	"description": "math/big: more conservative use of lock for divisor table\n\nMinor performance impact running sequentially:\n\nbenchmark                      old ns/op    new ns/op    delta\nBenchmarkString10Base2               389          391   +0.51%\nBenchmarkString100Base2             1530         1534   +0.26%\nBenchmarkString1000Base2           11789        11787   -0.02%\nBenchmarkString10000Base2         111443       112030   +0.53%\nBenchmarkString100000Base2       1017483      1015347   -0.21%\nBenchmarkString10Base8               339          344   +1.47%\nBenchmarkString100Base8              753          756   +0.40%\nBenchmarkString1000Base8            4618         4641   +0.50%\nBenchmarkString10000Base8          43217        43534   +0.73%\nBenchmarkString100000Base8        397518       400602   +0.78%\nBenchmarkString10Base10              630          630   +0.00%\nBenchmarkString100Base10            1975         1960   -0.76%\nBenchmarkString1000Base10          10179        10174   -0.05%\nBenchmarkString10000Base10         44527        44416   -0.25%\nBenchmarkString100000Base10     14404694     14425308   +0.14%\nBenchmarkString10Base16              283          288   +1.77%\nBenchmarkString100Base16             597          598   +0.17%\nBenchmarkString1000Base16           3189         3186   -0.09%\nBenchmarkString10000Base16         29403        29364   -0.13%\nBenchmarkString100000Base16       265657       265587   -0.03%\n\nNote that due to other improvements (faster assembly routines,\nbetter code generation by compiler), these benchmarks now run\nup to 37% faster than they used to at the last time measured (1/9/2012).\n\nMinor performance impact for StringPiParallel running in parallel:\n\nCurrent CL but with Lock/Unlock commented out (removed):\n\nBenchmarkStringPiParallel\t    5000\t    343581 ns/op\nBenchmarkStringPiParallel-2\t   10000\t    184511 ns/op\nBenchmarkStringPiParallel-3\t   10000\t    129768 ns/op\nBenchmarkStringPiParallel-4\t   10000\t    102326 ns/op\n\nCurrent CL:\n\nBenchmarkStringPiParallel\t    5000\t    345169 ns/op\nBenchmarkStringPiParallel-2\t   10000\t    185827 ns/op\nBenchmarkStringPiParallel-3\t   10000\t    131168 ns/op\nBenchmarkStringPiParallel-4\t   10000\t    102353 ns/op\n\nFixes issue 4218.",
	"cc": [
		"michael.jones@gmail.com",
		"dave@cheney.net",
		"golang-dev@googlegroups.com"
	],
	"reviewers": [
		"mtj@google.com",
		"dvyukov@google.com"
	],
	"messages": [
		{
			"sender": "gri@golang.org",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "PTAL.\n\nhttps://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go\nFile src/pkg/math/big/nat.go (right):\n\nhttps://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go#newcode925\nsrc/pkg/math/big/nat.go:925: mu    sync.Mutex  // protects table\nOn 2012/10/10 00:11:01, dfc wrote:\n> s/mu//\nbut of course! :-)",
			"disapproval": false,
			"date": "2012-10-10 00:15:05.811060",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello dvyukov@google.com, michael.jones@gmail.com (cc: golang-dev@googlegroups.com),\n\nI'd like you to review this change to\nhttps://code.google.com/p/go",
			"disapproval": false,
			"date": "2012-10-09 23:51:49.262280",
			"approval": false
		},
		{
			"sender": "dave@cheney.net",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "https://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go\nFile src/pkg/math/big/nat.go (right):\n\nhttps://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go#newcode925\nsrc/pkg/math/big/nat.go:925: mu    sync.Mutex  // protects table\ns/mu//\n\nhttps://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go#newcode949\nsrc/pkg/math/big/nat.go:949: cacheBase10.mu.Lock()\ns/mu//\n\nhttps://codereview.appspot.com/6643053/diff/3/src/pkg/math/big/nat.go#newcode950\nsrc/pkg/math/big/nat.go:950: defer cacheBase10.mu.Unlock()\nditto",
			"disapproval": false,
			"date": "2012-10-10 00:11:01.359990",
			"approval": false
		},
		{
			"sender": "dave@cheney.net",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Thank you. I'm not sure about this, I think the race still exists through table to the memory that it shares with cacheBase10.table.",
			"disapproval": false,
			"date": "2012-10-10 05:25:07.112590",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Wed, Oct 10, 2012 at 10:18 PM, <gri@golang.org> wrote:\r\n\r\n> PTAL.\r\n>\r\n> I am not concerned about the performance. Correctness trumps speed and\r\n> the performance degradation is small (0.5 - 1.5%) for the relevant\r\n> benchmarks (now attached).\r\n>\r\n\r\nThey are not parallel.\r\n\r\n\r\n>\r\n> I removed the defer statement for a minor improvement. Note that these\r\n> benchmarks run up to 37% faster\r\n\r\n\r\nMy parallel measurements show 121% degradation, so I guess now it is slower\r\nthan beginning of the year.\r\n\r\n\r\n\r\n> than they used to beginning of the year;\r\n> I suspect due to compiler improvements and due to the manual assembly\r\n> improvements for the core math routines. It's safer to tweak those\r\n> (there's more to get ouf of them) than trying lock-free approaches that\r\n> are hard to understand.\r\n>\r\n>\r\n>\r\n> On 2012/10/10 14:20:58, dvyukov wrote:\r\n>\r\n>> I do not see the race now, looks correct. But I am concerned about\r\n>>\r\n> performance\r\n>\r\n>> implications. On the following benchmark\r\n>>\r\n>\r\n>  func BenchmarkStringPi(b *testing.B) {\r\n>>         const STR =\r\n>>\r\n>\r\n> \"**123456789012345678990123456789**012345678990123456789012345678**\r\n> 990123456789012345678990123456**789012345678990123456789012345**\r\n> 678990123456789012345678990123**456789012345678990\"\r\n>\r\n>>         x, _, _ := nat(nil).scan(strings.**NewReader(STR), 10)\r\n>>         _ = x.decimalString()\r\n>>\r\n>\r\n>          procs := runtime.GOMAXPROCS(-1)\r\n>>         N := int32(b.N)\r\n>>         c := make(chan bool, procs)\r\n>>         for p := 0; p < procs; p++ {\r\n>>                 go func() {\r\n>>                         x, _, _ := nat(nil).scan(strings.**NewReader(STR),\r\n>> 10)\r\n>>                         for atomic.AddInt32(&N, -1) >= 0 {\r\n>>                                 _ = x.decimalString()\r\n>>                         }\r\n>>                         c <- true\r\n>>                 }()\r\n>>         }\r\n>>         for p := 0; p < procs; p++ {\r\n>>                 <-c\r\n>>         }\r\n>> }\r\n>>\r\n>\r\n>  w/o mutex lock/defer unlock:\r\n>>\r\n>\r\n>  BenchmarkStringPi         200000              4495 ns/op\r\n>> BenchmarkStringPi-4       500000              1484 ns/op\r\n>> BenchmarkStringPi-8      1000000               971 ns/op\r\n>> BenchmarkStringPi-16     1000000               738 ns/op\r\n>>\r\n>\r\n>  with mutex lock/defer unlock:\r\n>>\r\n>\r\n>  BenchmarkStringPi         200000              4708 ns/op\r\n>> BenchmarkStringPi-4       500000              1857 ns/op\r\n>> BenchmarkStringPi-8       500000              1555 ns/op\r\n>> BenchmarkStringPi-16      500000              1633 ns/op\r\n>>\r\n>\r\n>\r\n>  I would prefer lock-free fast path (but correct).\r\n>>\r\n>\r\n>\r\n>\r\n> https://codereview.appspot.**com/6643053/<https://codereview.appspot.com/6643053/>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-10 18:38:13.033490",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I'm still not concerned. Also, I cannot reproduce the slowdown you are\r\nreporting: I have added a parallel benchmark and it doesn't show the\r\nbehavior you are seing (albeit I can only go up to 4 on my machine).\r\nPerhaps there is contention in your benchmark on the benchmark side due to\r\nthe use of atomic?\r\n\r\nBut more importantly: This is about converting internal numbers to a\r\nhuman-readable decimal form for human consumption (for machine consumption,\r\nhex conversion would be more appropriate, way faster, and lock-free).\r\nOutputting large amounts of huge decimal numbers for human consumption is\r\nnot going to be the bottleneck of a program (if it is, there's probably\r\nsomething else wrong or it doesn't matter).\r\n\r\nOne approach is to fill in the entire table at initialization time, or at\r\nfirst use. I am not comfortable using atomic operations for some of the\r\nslice accesses - maybe I am wrong but I think it's very tricky to get\r\nright. Happy to be proven otherwise.\r\n\r\nAgain, this is about correctness first and fixing the issue, performance\r\n2nd; and as far as I can tell, performance is ok. If it's becoming a real\r\nissue for a real application, we can dive into it more.\r\n- gri\r\n\r\n\r\nOn Wed, Oct 10, 2012 at 11:38 AM, Dmitry Vyukov <dvyukov@google.com> wrote:\r\n\r\n> On Wed, Oct 10, 2012 at 10:18 PM, <gri@golang.org> wrote:\r\n>\r\n>> PTAL.\r\n>>\r\n>> I am not concerned about the performance. Correctness trumps speed and\r\n>> the performance degradation is small (0.5 - 1.5%) for the relevant\r\n>> benchmarks (now attached).\r\n>>\r\n>\r\n> They are not parallel.\r\n>\r\n>\r\n>>\r\n>> I removed the defer statement for a minor improvement. Note that these\r\n>> benchmarks run up to 37% faster\r\n>\r\n>\r\n> My parallel measurements show 121% degradation, so I guess now it is\r\n> slower than beginning of the year.\r\n>\r\n>\r\n>\r\n>> than they used to beginning of the year;\r\n>> I suspect due to compiler improvements and due to the manual assembly\r\n>> improvements for the core math routines. It's safer to tweak those\r\n>> (there's more to get ouf of them) than trying lock-free approaches that\r\n>> are hard to understand.\r\n>>\r\n>>\r\n>>\r\n>> On 2012/10/10 14:20:58, dvyukov wrote:\r\n>>\r\n>>> I do not see the race now, looks correct. But I am concerned about\r\n>>>\r\n>> performance\r\n>>\r\n>>> implications. On the following benchmark\r\n>>>\r\n>>\r\n>>  func BenchmarkStringPi(b *testing.B) {\r\n>>>         const STR =\r\n>>>\r\n>>\r\n>> \"**123456789012345678990123456789**012345678990123456789012345678**\r\n>> 990123456789012345678990123456**789012345678990123456789012345**\r\n>> 678990123456789012345678990123**456789012345678990\"\r\n>>\r\n>>>         x, _, _ := nat(nil).scan(strings.**NewReader(STR), 10)\r\n>>>         _ = x.decimalString()\r\n>>>\r\n>>\r\n>>          procs := runtime.GOMAXPROCS(-1)\r\n>>>         N := int32(b.N)\r\n>>>         c := make(chan bool, procs)\r\n>>>         for p := 0; p < procs; p++ {\r\n>>>                 go func() {\r\n>>>                         x, _, _ := nat(nil).scan(strings.**NewReader(STR),\r\n>>> 10)\r\n>>>                         for atomic.AddInt32(&N, -1) >= 0 {\r\n>>>                                 _ = x.decimalString()\r\n>>>                         }\r\n>>>                         c <- true\r\n>>>                 }()\r\n>>>         }\r\n>>>         for p := 0; p < procs; p++ {\r\n>>>                 <-c\r\n>>>         }\r\n>>> }\r\n>>>\r\n>>\r\n>>  w/o mutex lock/defer unlock:\r\n>>>\r\n>>\r\n>>  BenchmarkStringPi         200000              4495 ns/op\r\n>>> BenchmarkStringPi-4       500000              1484 ns/op\r\n>>> BenchmarkStringPi-8      1000000               971 ns/op\r\n>>> BenchmarkStringPi-16     1000000               738 ns/op\r\n>>>\r\n>>\r\n>>  with mutex lock/defer unlock:\r\n>>>\r\n>>\r\n>>  BenchmarkStringPi         200000              4708 ns/op\r\n>>> BenchmarkStringPi-4       500000              1857 ns/op\r\n>>> BenchmarkStringPi-8       500000              1555 ns/op\r\n>>> BenchmarkStringPi-16      500000              1633 ns/op\r\n>>>\r\n>>\r\n>>\r\n>>  I would prefer lock-free fast path (but correct).\r\n>>>\r\n>>\r\n>>\r\n>>\r\n>> https://codereview.appspot.**com/6643053/<https://codereview.appspot.com/6643053/>\r\n>>\r\n>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-10 20:51:36.412010",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I do not see the race now, looks correct. But I am concerned about performance implications. On the following benchmark\n\nfunc BenchmarkStringPi(b *testing.B) {\n\tconst STR = \"123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990\"\n\tx, _, _ := nat(nil).scan(strings.NewReader(STR), 10)\n\t_ = x.decimalString()\n\n\tprocs := runtime.GOMAXPROCS(-1)\n\tN := int32(b.N)\n\tc := make(chan bool, procs)\n\tfor p := 0; p < procs; p++ {\n\t\tgo func() {\n\t\t\tx, _, _ := nat(nil).scan(strings.NewReader(STR), 10)\n\t\t\tfor atomic.AddInt32(&N, -1) >= 0 {\n\t\t\t\t_ = x.decimalString()\n\t\t\t}\n\t\t\tc <- true\n\t\t}()\n\t}\n\tfor p := 0; p < procs; p++ {\n\t\t<-c\n\t}\n}\n\nw/o mutex lock/defer unlock:\n\nBenchmarkStringPi\t  200000\t      4495 ns/op\nBenchmarkStringPi-4\t  500000\t      1484 ns/op\nBenchmarkStringPi-8\t 1000000\t       971 ns/op\nBenchmarkStringPi-16\t 1000000\t       738 ns/op\n\nwith mutex lock/defer unlock:\n\nBenchmarkStringPi\t  200000\t      4708 ns/op\nBenchmarkStringPi-4\t  500000\t      1857 ns/op\nBenchmarkStringPi-8\t  500000\t      1555 ns/op\nBenchmarkStringPi-16\t  500000\t      1633 ns/op\n\n\nI would prefer lock-free fast path (but correct).",
			"disapproval": false,
			"date": "2012-10-10 14:20:58.920170",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "PTAL.\n\nI am not concerned about the performance. Correctness trumps speed and the performance degradation is small (0.5 - 1.5%) for the relevant benchmarks (now attached).\n\nI removed the defer statement for a minor improvement. Note that these benchmarks run up to 37% faster than they used to beginning of the year; I suspect due to compiler improvements and due to the manual assembly improvements for the core math routines. It's safer to tweak those (there's more to get ouf of them) than trying lock-free approaches that are hard to understand.\n\n\nOn 2012/10/10 14:20:58, dvyukov wrote:\n> I do not see the race now, looks correct. But I am concerned about performance\n> implications. On the following benchmark\n> \n> func BenchmarkStringPi(b *testing.B) {\n> \tconst STR =\n> \"123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990123456789012345678990\"\n> \tx, _, _ := nat(nil).scan(strings.NewReader(STR), 10)\n> \t_ = x.decimalString()\n> \n> \tprocs := runtime.GOMAXPROCS(-1)\n> \tN := int32(b.N)\n> \tc := make(chan bool, procs)\n> \tfor p := 0; p < procs; p++ {\n> \t\tgo func() {\n> \t\t\tx, _, _ := nat(nil).scan(strings.NewReader(STR), 10)\n> \t\t\tfor atomic.AddInt32(&N, -1) >= 0 {\n> \t\t\t\t_ = x.decimalString()\n> \t\t\t}\n> \t\t\tc <- true\n> \t\t}()\n> \t}\n> \tfor p := 0; p < procs; p++ {\n> \t\t<-c\n> \t}\n> }\n> \n> w/o mutex lock/defer unlock:\n> \n> BenchmarkStringPi\t  200000\t      4495 ns/op\n> BenchmarkStringPi-4\t  500000\t      1484 ns/op\n> BenchmarkStringPi-8\t 1000000\t       971 ns/op\n> BenchmarkStringPi-16\t 1000000\t       738 ns/op\n> \n> with mutex lock/defer unlock:\n> \n> BenchmarkStringPi\t  200000\t      4708 ns/op\n> BenchmarkStringPi-4\t  500000\t      1857 ns/op\n> BenchmarkStringPi-8\t  500000\t      1555 ns/op\n> BenchmarkStringPi-16\t  500000\t      1633 ns/op\n> \n> \n> I would prefer lock-free fast path (but correct).",
			"disapproval": false,
			"date": "2012-10-10 18:18:41.909470",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello dvyukov@google.com, michael.jones@gmail.com, dave@cheney.net (cc: golang-dev@googlegroups.com),\n\nPlease take another look.",
			"disapproval": false,
			"date": "2012-10-10 20:51:53.138320",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Looks correct to me",
			"disapproval": false,
			"date": "2012-10-11 04:20:05.889870",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Dmitry;\r\n\r\nCan you please give this CL a LGTM if you're ok with it now? That way I can\r\nsubmit it. Thanks.\r\n\r\nhttps://codereview.appspot.**com/6643053/<https://codereview.appspot.com/6643053/>\r\n\r\n- Robert\r\n",
			"disapproval": false,
			"date": "2012-10-11 16:38:29.075980",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Lgtm\r\nOn Oct 11, 2012 8:38 PM, \"Robert Griesemer\" <gri@golang.org> wrote:\r\n\r\n> Dmitry;\r\n>\r\n> Can you please give this CL a LGTM if you're ok with it now? That way I\r\n> can submit it. Thanks.\r\n>\r\n> https://codereview.appspot.**com/6643053/<https://codereview.appspot.com/6643053/>\r\n>\r\n> - Robert\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-11 20:01:20.645920",
			"approval": true
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"gri@golang.org",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "*** Submitted as http://code.google.com/p/go/source/detail?r=57e13fc87f43 ***\n\nmath/big: more conservative use of lock for divisor table\n\nMinor performance impact running sequentially:\n\nbenchmark                      old ns/op    new ns/op    delta\nBenchmarkString10Base2               389          391   +0.51%\nBenchmarkString100Base2             1530         1534   +0.26%\nBenchmarkString1000Base2           11789        11787   -0.02%\nBenchmarkString10000Base2         111443       112030   +0.53%\nBenchmarkString100000Base2       1017483      1015347   -0.21%\nBenchmarkString10Base8               339          344   +1.47%\nBenchmarkString100Base8              753          756   +0.40%\nBenchmarkString1000Base8            4618         4641   +0.50%\nBenchmarkString10000Base8          43217        43534   +0.73%\nBenchmarkString100000Base8        397518       400602   +0.78%\nBenchmarkString10Base10              630          630   +0.00%\nBenchmarkString100Base10            1975         1960   -0.76%\nBenchmarkString1000Base10          10179        10174   -0.05%\nBenchmarkString10000Base10         44527        44416   -0.25%\nBenchmarkString100000Base10     14404694     14425308   +0.14%\nBenchmarkString10Base16              283          288   +1.77%\nBenchmarkString100Base16             597          598   +0.17%\nBenchmarkString1000Base16           3189         3186   -0.09%\nBenchmarkString10000Base16         29403        29364   -0.13%\nBenchmarkString100000Base16       265657       265587   -0.03%\n\nNote that due to other improvements (faster assembly routines,\nbetter code generation by compiler), these benchmarks now run\nup to 37% faster than they used to at the last time measured (1/9/2012).\n\nMinor performance impact for StringPiParallel running in parallel:\n\nCurrent CL but with Lock/Unlock commented out (removed):\n\nBenchmarkStringPiParallel\t    5000\t    343581 ns/op\nBenchmarkStringPiParallel-2\t   10000\t    184511 ns/op\nBenchmarkStringPiParallel-3\t   10000\t    129768 ns/op\nBenchmarkStringPiParallel-4\t   10000\t    102326 ns/op\n\nCurrent CL:\n\nBenchmarkStringPiParallel\t    5000\t    345169 ns/op\nBenchmarkStringPiParallel-2\t   10000\t    185827 ns/op\nBenchmarkStringPiParallel-3\t   10000\t    131168 ns/op\nBenchmarkStringPiParallel-4\t   10000\t    102353 ns/op\n\nFixes issue 4218.\n\nR=dvyukov, michael.jones, dave\nCC=golang-dev\nhttp://codereview.appspot.com/6643053",
			"disapproval": false,
			"date": "2012-10-11 23:04:08.231640",
			"approval": false
		},
		{
			"sender": "michael.jones@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Just seeing this now (email was to a mostly unused personal account rather\r\nthan my work account.)\r\n\r\nThe blocking and concurrent-waiting on data around this structure is by\r\ndesign.\r\n\r\nTo run fast, when there are two or more large numbers to be converted from\r\ninternal base 2^n to external base 10 (say, but for any base not a power of\r\ntwo), then we need a table of divisors. For a (say million \"word\" number\r\nN), we need N**(1/2), N**(1/4), N**(1/8), .. down to a \"small\" size, say\r\n8-words.  where \"**\" is the exponentiation operator. This table can be big,\r\nhowever, it can be built just once and reused many times. The code does\r\nthis now.\r\n\r\nWhen a first big (bigger than the existing table size) conversion is\r\nneeded, the code updates the table. When more than one goroutine tries the\r\nsame large conversion at the same time, then the first one builds the table\r\nand the rest of them wait for each entry to be built. Building them\r\nredundantly would be no faster and wastes memory and CPU. Once the table\r\ngrows suitably, then this phase is a no-op as the table is cached.\r\n\r\nWhile we could wish that the table was already built, or that as in a real\r\nprogram we might assume that a first operation builds the table without\r\nother threads waiting, in the benchmark case of all goroutines converting\r\nthe same number will cause delays for the first iterations.\r\n\r\nI see no better way.\r\n\r\nMichael\r\n\r\nOn Thu, Oct 11, 2012 at 4:04 PM, <gri@golang.org> wrote:\r\n\r\n> *** Submitted as\r\n> http://code.google.com/p/go/**source/detail?r=57e13fc87f43<http://code.google.com/p/go/source/detail?r=57e13fc87f43>***\r\n>\r\n>\r\n> math/big: more conservative use of lock for divisor table\r\n>\r\n> Minor performance impact running sequentially:\r\n>\r\n> benchmark                      old ns/op    new ns/op    delta\r\n> BenchmarkString10Base2               389          391   +0.51%\r\n> BenchmarkString100Base2             1530         1534   +0.26%\r\n> BenchmarkString1000Base2           11789        11787   -0.02%\r\n> BenchmarkString10000Base2         111443       112030   +0.53%\r\n> BenchmarkString100000Base2       1017483      1015347   -0.21%\r\n> BenchmarkString10Base8               339          344   +1.47%\r\n> BenchmarkString100Base8              753          756   +0.40%\r\n> BenchmarkString1000Base8            4618         4641   +0.50%\r\n> BenchmarkString10000Base8          43217        43534   +0.73%\r\n> BenchmarkString100000Base8        397518       400602   +0.78%\r\n> BenchmarkString10Base10              630          630   +0.00%\r\n> BenchmarkString100Base10            1975         1960   -0.76%\r\n> BenchmarkString1000Base10          10179        10174   -0.05%\r\n> BenchmarkString10000Base10         44527        44416   -0.25%\r\n> BenchmarkString100000Base10     14404694     14425308   +0.14%\r\n> BenchmarkString10Base16              283          288   +1.77%\r\n> BenchmarkString100Base16             597          598   +0.17%\r\n> BenchmarkString1000Base16           3189         3186   -0.09%\r\n> BenchmarkString10000Base16         29403        29364   -0.13%\r\n> BenchmarkString100000Base16       265657       265587   -0.03%\r\n>\r\n> Note that due to other improvements (faster assembly routines,\r\n> better code generation by compiler), these benchmarks now run\r\n> up to 37% faster than they used to at the last time measured (1/9/2012).\r\n>\r\n> Minor performance impact for StringPiParallel running in parallel:\r\n>\r\n> Current CL but with Lock/Unlock commented out (removed):\r\n>\r\n> BenchmarkStringPiParallel           5000            343581 ns/op\r\n> BenchmarkStringPiParallel-2        10000            184511 ns/op\r\n> BenchmarkStringPiParallel-3        10000            129768 ns/op\r\n> BenchmarkStringPiParallel-4        10000            102326 ns/op\r\n>\r\n> Current CL:\r\n>\r\n> BenchmarkStringPiParallel           5000            345169 ns/op\r\n> BenchmarkStringPiParallel-2        10000            185827 ns/op\r\n> BenchmarkStringPiParallel-3        10000            131168 ns/op\r\n> BenchmarkStringPiParallel-4        10000            102353 ns/op\r\n>\r\n> Fixes issue 4218.\r\n>\r\n> R=dvyukov, michael.jones, dave\r\n> CC=golang-dev\r\n> http://codereview.appspot.com/**6643053<http://codereview.appspot.com/6643053>\r\n>\r\n>\r\n> http://codereview.appspot.com/**6643053/<http://codereview.appspot.com/6643053/>\r\n>\r\n\r\n\r\n\r\n-- \r\nMichael T. Jones\r\nmichael.jones@gmail.com\r\nhttp://www.google.com/profiles/michael.jones\r\n",
			"disapproval": false,
			"date": "2012-10-13 14:50:57.338540",
			"approval": false
		},
		{
			"sender": "michael.jones@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I said that wrong (just woke up). It's not so much n**(1/2), n**(1/4).. as\r\nit is the other way, the largest power of 10 (say) that fits in a Word, and\r\nthen that value **2, **4, **8, and so on until we ge close to the sqrt(N).\r\nThe essence is the same.\r\n\r\nOn Sat, Oct 13, 2012 at 7:50 AM, Michael Jones <michael.jones@gmail.com>wrote:\r\n\r\n> Just seeing this now (email was to a mostly unused personal account rather\r\n> than my work account.)\r\n>\r\n> The blocking and concurrent-waiting on data around this structure is by\r\n> design.\r\n>\r\n> To run fast, when there are two or more large numbers to be converted from\r\n> internal base 2^n to external base 10 (say, but for any base not a power of\r\n> two), then we need a table of divisors. For a (say million \"word\" number\r\n> N), we need N**(1/2), N**(1/4), N**(1/8), .. down to a \"small\" size, say\r\n> 8-words.  where \"**\" is the exponentiation operator. This table can be big,\r\n> however, it can be built just once and reused many times. The code does\r\n> this now.\r\n>\r\n> When a first big (bigger than the existing table size) conversion is\r\n> needed, the code updates the table. When more than one goroutine tries the\r\n> same large conversion at the same time, then the first one builds the table\r\n> and the rest of them wait for each entry to be built. Building them\r\n> redundantly would be no faster and wastes memory and CPU. Once the table\r\n> grows suitably, then this phase is a no-op as the table is cached.\r\n>\r\n> While we could wish that the table was already built, or that as in a real\r\n> program we might assume that a first operation builds the table without\r\n> other threads waiting, in the benchmark case of all goroutines converting\r\n> the same number will cause delays for the first iterations.\r\n>\r\n> I see no better way.\r\n>\r\n> Michael\r\n>\r\n> On Thu, Oct 11, 2012 at 4:04 PM, <gri@golang.org> wrote:\r\n>\r\n>> *** Submitted as\r\n>> http://code.google.com/p/go/**source/detail?r=57e13fc87f43<http://code.google.com/p/go/source/detail?r=57e13fc87f43>***\r\n>>\r\n>>\r\n>> math/big: more conservative use of lock for divisor table\r\n>>\r\n>> Minor performance impact running sequentially:\r\n>>\r\n>> benchmark                      old ns/op    new ns/op    delta\r\n>> BenchmarkString10Base2               389          391   +0.51%\r\n>> BenchmarkString100Base2             1530         1534   +0.26%\r\n>> BenchmarkString1000Base2           11789        11787   -0.02%\r\n>> BenchmarkString10000Base2         111443       112030   +0.53%\r\n>> BenchmarkString100000Base2       1017483      1015347   -0.21%\r\n>> BenchmarkString10Base8               339          344   +1.47%\r\n>> BenchmarkString100Base8              753          756   +0.40%\r\n>> BenchmarkString1000Base8            4618         4641   +0.50%\r\n>> BenchmarkString10000Base8          43217        43534   +0.73%\r\n>> BenchmarkString100000Base8        397518       400602   +0.78%\r\n>> BenchmarkString10Base10              630          630   +0.00%\r\n>> BenchmarkString100Base10            1975         1960   -0.76%\r\n>> BenchmarkString1000Base10          10179        10174   -0.05%\r\n>> BenchmarkString10000Base10         44527        44416   -0.25%\r\n>> BenchmarkString100000Base10     14404694     14425308   +0.14%\r\n>> BenchmarkString10Base16              283          288   +1.77%\r\n>> BenchmarkString100Base16             597          598   +0.17%\r\n>> BenchmarkString1000Base16           3189         3186   -0.09%\r\n>> BenchmarkString10000Base16         29403        29364   -0.13%\r\n>> BenchmarkString100000Base16       265657       265587   -0.03%\r\n>>\r\n>> Note that due to other improvements (faster assembly routines,\r\n>> better code generation by compiler), these benchmarks now run\r\n>> up to 37% faster than they used to at the last time measured (1/9/2012).\r\n>>\r\n>> Minor performance impact for StringPiParallel running in parallel:\r\n>>\r\n>> Current CL but with Lock/Unlock commented out (removed):\r\n>>\r\n>> BenchmarkStringPiParallel           5000            343581 ns/op\r\n>> BenchmarkStringPiParallel-2        10000            184511 ns/op\r\n>> BenchmarkStringPiParallel-3        10000            129768 ns/op\r\n>> BenchmarkStringPiParallel-4        10000            102326 ns/op\r\n>>\r\n>> Current CL:\r\n>>\r\n>> BenchmarkStringPiParallel           5000            345169 ns/op\r\n>> BenchmarkStringPiParallel-2        10000            185827 ns/op\r\n>> BenchmarkStringPiParallel-3        10000            131168 ns/op\r\n>> BenchmarkStringPiParallel-4        10000            102353 ns/op\r\n>>\r\n>> Fixes issue 4218.\r\n>>\r\n>> R=dvyukov, michael.jones, dave\r\n>> CC=golang-dev\r\n>> http://codereview.appspot.com/**6643053<http://codereview.appspot.com/6643053>\r\n>>\r\n>>\r\n>> http://codereview.appspot.com/**6643053/<http://codereview.appspot.com/6643053/>\r\n>>\r\n>\r\n>\r\n>\r\n> --\r\n> Michael T. Jones\r\n> michael.jones@gmail.com\r\n> http://www.google.com/profiles/michael.jones\r\n>\r\n\r\n\r\n\r\n-- \r\nMichael T. Jones\r\nmichael.jones@gmail.com\r\nhttp://www.google.com/profiles/michael.jones\r\n",
			"disapproval": false,
			"date": "2012-10-13 15:03:33.103250",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Sat, Oct 13, 2012 at 6:50 PM, Michael Jones <michael.jones@gmail.com>wrote:\r\n\r\n> Just seeing this now (email was to a mostly unused personal account rather\r\n> than my work account.)\r\n>\r\n> The blocking and concurrent-waiting on data around this structure is by\r\n> design.\r\n>\r\n> To run fast, when there are two or more large numbers to be converted from\r\n> internal base 2^n to external base 10 (say, but for any base not a power of\r\n> two), then we need a table of divisors. For a (say million \"word\" number\r\n> N), we need N**(1/2), N**(1/4), N**(1/8), .. down to a \"small\" size, say\r\n> 8-words.  where \"**\" is the exponentiation operator. This table can be big,\r\n> however, it can be built just once and reused many times. The code does\r\n> this now.\r\n>\r\n> When a first big (bigger than the existing table size) conversion is\r\n> needed, the code updates the table. When more than one goroutine tries the\r\n> same large conversion at the same time, then the first one builds the table\r\n> and the rest of them wait for each entry to be built. Building them\r\n> redundantly would be no faster and wastes memory and CPU. Once the table\r\n> grows suitably, then this phase is a no-op as the table is cached.\r\n>\r\n> While we could wish that the table was already built, or that as in a real\r\n> program we might assume that a first operation builds the table without\r\n> other threads waiting, in the benchmark case of all goroutines converting\r\n> the same number will cause delays for the first iterations.\r\n>\r\n> I see no better way.\r\n>\r\n> Michael\r\n>\r\n\r\n\r\nThere is only one problem. The code does a different thing, that leads to\r\ndata races, crashes and exceptions.\r\nI suggested to Robert to make the code work the way you describe.\r\n\r\n\r\n\r\n> kString10Base2               389          391   +0.51%\r\n>\r\n>> BenchmarkString100Base2             1530         1534   +0.26%\r\n>> BenchmarkString1000Base2           11789        11787   -0.02%\r\n>> BenchmarkString10000Base2         111443       112030   +0.53%\r\n>> BenchmarkString100000Base2       1017483      1015347   -0.21%\r\n>> BenchmarkString10Base8               339          344   +1.47%\r\n>> BenchmarkString100Base8              753          756   +0.40%\r\n>> BenchmarkString1000Base8            4618         4641   +0.50%\r\n>> BenchmarkString10000Base8          43217        43534   +0.73%\r\n>> BenchmarkString100000Base8        397518       400602   +0.78%\r\n>> BenchmarkString10Base10              630          630   +0.00%\r\n>> BenchmarkString100Base10            1975         1960   -0.76%\r\n>> BenchmarkString1000Base10          10179        10174   -0.05%\r\n>> BenchmarkString10000Base10         44527        44416   -0.25%\r\n>> BenchmarkString100000Base10     14404694     14425308   +0.14%\r\n>> BenchmarkString10Base16              283          288   +1.77%\r\n>> BenchmarkString100Base16             597          598   +0.17%\r\n>> BenchmarkString1000Base16           3189         3186   -0.09%\r\n>> BenchmarkString10000Base16         29403        29364   -0.13%\r\n>> BenchmarkString100000Base16       265657       265587   -0.03%\r\n>>\r\n>> Note that due to other improvements (faster assembly routines,\r\n>> better code generation by compiler), these benchmarks now run\r\n>> up to 37% faster than they used to at the last time measured (1/9/2012).\r\n>>\r\n>> Minor performance impact for StringPiParallel running in parallel:\r\n>>\r\n>> Current CL but with Lock/Unlock commented out (removed):\r\n>>\r\n>> BenchmarkStringPiParallel           5000            343581 ns/op\r\n>> BenchmarkStringPiParallel-2        10000            184511 ns/op\r\n>> BenchmarkStringPiParallel-3        10000            129768 ns/op\r\n>> BenchmarkStringPiParallel-4        10000            102326 ns/op\r\n>>\r\n>> Current CL:\r\n>>\r\n>> BenchmarkStringPiParallel           5000            345169 ns/op\r\n>> BenchmarkStringPiParallel-2        10000            185827 ns/op\r\n>> BenchmarkStringPiParallel-3        10000            131168 ns/op\r\n>> BenchmarkStringPiParallel-4        10000            102353 ns/op\r\n>>\r\n>> Fixes issue 4218.\r\n>>\r\n>> R=dvyukov, michael.jones, dave\r\n>> CC=golang-dev\r\n>> http://codereview.appspot.com/**6643053<http://codereview.appspot.com/6643053>\r\n>>\r\n>>\r\n>> http://codereview.appspot.com/**6643053/<http://codereview.appspot.com/6643053/>\r\n>>\r\n>\r\n>\r\n>\r\n> --\r\n> Michael T. Jones\r\n> michael.jones@gmail.com\r\n> http://www.google.com/profiles/michael.jones\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-14 09:05:22.481990",
			"approval": false
		},
		{
			"sender": "mtj@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Thanks! Performance wise, it is important that other goroutines be able to\r\nuse the read-only smaller entries while a larger one is being created.\r\n\r\nOn Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com> wrote:\r\n\r\n> I suggested to Robert to make the code work the way you describe.\r\n\r\n\r\n\r\n\r\n-- \r\nMichael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n650-335-5765\r\n",
			"disapproval": false,
			"date": "2012-10-14 12:46:00.231050",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "It is not the case now.\r\n\r\n\r\nOn Sun, Oct 14, 2012 at 4:45 PM, Michael Jones <mtj@google.com> wrote:\r\n\r\n> Thanks! Performance wise, it is important that other goroutines be able to\r\n> use the read-only smaller entries while a larger one is being created.\r\n>\r\n>\r\n> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com> wrote:\r\n>\r\n>> I suggested to Robert to make the code work the way you describe.\r\n>\r\n>\r\n>\r\n>\r\n> --\r\n> Michael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n> 650-335-5765\r\n>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-15 10:31:23.268100",
			"approval": false
		},
		{
			"sender": "michael.jones@gmail.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Ok. Will look. Thank you for bringing this to my attention!\r\n\r\nOn Mon, Oct 15, 2012 at 3:31 AM, Dmitry Vyukov <dvyukov@google.com> wrote:\r\n\r\n> It is not the case now.\r\n>\r\n>\r\n> On Sun, Oct 14, 2012 at 4:45 PM, Michael Jones <mtj@google.com> wrote:\r\n>\r\n>> Thanks! Performance wise, it is important that other goroutines be able\r\n>> to use the read-only smaller entries while a larger one is being created.\r\n>>\r\n>>\r\n>> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com>wrote:\r\n>>\r\n>>> I suggested to Robert to make the code work the way you describe.\r\n>>\r\n>>\r\n>>\r\n>>\r\n>>  --\r\n>> Michael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n>> 650-335-5765\r\n>>\r\n>>\r\n>\r\n\r\n\r\n-- \r\nMichael T. Jones\r\nmichael.jones@gmail.com\r\nhttp://www.google.com/profiles/michael.jones\r\n",
			"disapproval": false,
			"date": "2012-10-15 20:51:58.647140",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "The only safe way I see at the moment to do this is to lock/unlock the\r\nmutex for each new table entry. That's not hard, but I don't know if it's\r\nworth it. I am worried about correctness of lock-free approaches (using\r\npackage atomic) that operate on slice elements. But I'm happy to be proven\r\notherwise. Either way, I believe what we have now is correct if possible\r\nnot optimal performance-wise. But again, I don't think there's an immediate\r\nurgency for this to be fixed as I am not aware of programs caring about\r\nthis too much at the moment.\r\n- gri\r\n\r\n\r\nOn Mon, Oct 15, 2012 at 1:51 PM, Michael Jones <michael.jones@gmail.com>wrote:\r\n\r\n> Ok. Will look. Thank you for bringing this to my attention!\r\n>\r\n>\r\n> On Mon, Oct 15, 2012 at 3:31 AM, Dmitry Vyukov <dvyukov@google.com> wrote:\r\n>\r\n>> It is not the case now.\r\n>>\r\n>>\r\n>> On Sun, Oct 14, 2012 at 4:45 PM, Michael Jones <mtj@google.com> wrote:\r\n>>\r\n>>> Thanks! Performance wise, it is important that other goroutines be able\r\n>>> to use the read-only smaller entries while a larger one is being created.\r\n>>>\r\n>>>\r\n>>> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com>wrote:\r\n>>>\r\n>>>> I suggested to Robert to make the code work the way you describe.\r\n>>>\r\n>>>\r\n>>>\r\n>>>\r\n>>>  --\r\n>>> Michael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n>>> 650-335-5765\r\n>>>\r\n>>>\r\n>>\r\n>\r\n>\r\n> --\r\n> Michael T. Jones\r\n> michael.jones@gmail.com\r\n> http://www.google.com/profiles/michael.jones\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-15 21:35:07.305030",
			"approval": false
		},
		{
			"sender": "mtj@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "OK.\r\nOn Oct 15, 2012 2:35 PM, \"Robert Griesemer\" <gri@golang.org> wrote:\r\n\r\n> The only safe way I see at the moment to do this is to lock/unlock the\r\n> mutex for each new table entry. That's not hard, but I don't know if it's\r\n> worth it. I am worried about correctness of lock-free approaches (using\r\n> package atomic) that operate on slice elements. But I'm happy to be proven\r\n> otherwise. Either way, I believe what we have now is correct if possible\r\n> not optimal performance-wise. But again, I don't think there's an immediate\r\n> urgency for this to be fixed as I am not aware of programs caring about\r\n> this too much at the moment.\r\n> - gri\r\n>\r\n>\r\n> On Mon, Oct 15, 2012 at 1:51 PM, Michael Jones <michael.jones@gmail.com>wrote:\r\n>\r\n>> Ok. Will look. Thank you for bringing this to my attention!\r\n>>\r\n>>\r\n>> On Mon, Oct 15, 2012 at 3:31 AM, Dmitry Vyukov <dvyukov@google.com>wrote:\r\n>>\r\n>>> It is not the case now.\r\n>>>\r\n>>>\r\n>>> On Sun, Oct 14, 2012 at 4:45 PM, Michael Jones <mtj@google.com> wrote:\r\n>>>\r\n>>>> Thanks! Performance wise, it is important that other goroutines be able\r\n>>>> to use the read-only smaller entries while a larger one is being created.\r\n>>>>\r\n>>>>\r\n>>>> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com>wrote:\r\n>>>>\r\n>>>>> I suggested to Robert to make the code work the way you describe.\r\n>>>>\r\n>>>>\r\n>>>>\r\n>>>>\r\n>>>>  --\r\n>>>> Michael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n>>>> 650-335-5765\r\n>>>>\r\n>>>>\r\n>>>\r\n>>\r\n>>\r\n>> --\r\n>> Michael T. Jones\r\n>> michael.jones@gmail.com\r\n>> http://www.google.com/profiles/michael.jones\r\n>>\r\n>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-10-15 22:07:39.427980",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"gri@golang.org",
				"mtj@google.com",
				"dvyukov@google.com",
				"michael.jones@gmail.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2012/10/15 21:35:07, gri wrote:\n> The only safe way I see at the moment to do this is to lock/unlock the\n> mutex for each new table entry. That's not hard, but I don't know if it's\n> worth it. I am worried about correctness of lock-free approaches (using\n> package atomic) that operate on slice elements. But I'm happy to be proven\n> otherwise. Either way, I believe what we have now is correct if possible\n> not optimal performance-wise. But again, I don't think there's an immediate\n> urgency for this to be fixed as I am not aware of programs caring about\n> this too much at the moment.\n> - gri\n\n\nIt's quite easy to implement w/o atomic ops on slice elements. That's what I had in mind:\nhttps://codereview.appspot.com/6766047/diff/2001/src/pkg/math/big/nat.go\n\n\n\n> On Mon, Oct 15, 2012 at 1:51 PM, Michael Jones <michael.jones@gmail.com>wrote:\n> \n> > Ok. Will look. Thank you for bringing this to my attention!\n> >\n> >\n> > On Mon, Oct 15, 2012 at 3:31 AM, Dmitry Vyukov <mailto:dvyukov@google.com> wrote:\n> >\n> >> It is not the case now.\n> >>\n> >>\n> >> On Sun, Oct 14, 2012 at 4:45 PM, Michael Jones <mailto:mtj@google.com> wrote:\n> >>\n> >>> Thanks! Performance wise, it is important that other goroutines be able\n> >>> to use the read-only smaller entries while a larger one is being created.\n> >>>\n> >>>\n> >>> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov <dvyukov@google.com>wrote:\n> >>>\n> >>>> I suggested to Robert to make the code work the way you describe.\n> >>>\n> >>>\n> >>>\n> >>>\n> >>>  --\n> >>> Michael T. Jones | Chief Technology Advocate  | mailto:mtj@google.com |  +1\n> >>> 650-335-5765\n> >>>\n> >>>\n> >>\n> >\n> >\n> > --\n> > Michael T. Jones\n> > mailto:michael.jones@gmail.com\n> > http://www.google.com/profiles/michael.jones\n> >",
			"disapproval": false,
			"date": "2012-10-24 19:03:50.649200",
			"approval": false
		},
		{
			"sender": "mtj@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "In an airport on the way to Cypress. Will look ASAP.\r\n\r\nOn Wed, Oct 24, 2012 at 12:03 PM,  <dvyukov@google.com> wrote:\r\n> On 2012/10/15 21:35:07, gri wrote:\r\n>>\r\n>> The only safe way I see at the moment to do this is to lock/unlock the\r\n>> mutex for each new table entry. That's not hard, but I don't know if\r\n>\r\n> it's\r\n>>\r\n>> worth it. I am worried about correctness of lock-free approaches\r\n>\r\n> (using\r\n>>\r\n>> package atomic) that operate on slice elements. But I'm happy to be\r\n>\r\n> proven\r\n>>\r\n>> otherwise. Either way, I believe what we have now is correct if\r\n>\r\n> possible\r\n>>\r\n>> not optimal performance-wise. But again, I don't think there's an\r\n>\r\n> immediate\r\n>>\r\n>> urgency for this to be fixed as I am not aware of programs caring\r\n>\r\n> about\r\n>>\r\n>> this too much at the moment.\r\n>> - gri\r\n>\r\n>\r\n>\r\n> It's quite easy to implement w/o atomic ops on slice elements. That's\r\n> what I had in mind:\r\n> https://codereview.appspot.com/6766047/diff/2001/src/pkg/math/big/nat.go\r\n>\r\n>\r\n>\r\n>> On Mon, Oct 15, 2012 at 1:51 PM, Michael Jones\r\n>\r\n> <michael.jones@gmail.com>wrote:\r\n>\r\n>> > Ok. Will look. Thank you for bringing this to my attention!\r\n>> >\r\n>> >\r\n>> > On Mon, Oct 15, 2012 at 3:31 AM, Dmitry Vyukov\r\n>\r\n> <mailto:dvyukov@google.com> wrote:\r\n>>\r\n>> >\r\n>> >> It is not the case now.\r\n>> >>\r\n>> >>\r\n>> >> On Sun, Oct 14, 2012 at 4:45 PM, Michael Jones\r\n>\r\n> <mailto:mtj@google.com> wrote:\r\n>>\r\n>> >>\r\n>> >>> Thanks! Performance wise, it is important that other goroutines be\r\n>\r\n> able\r\n>>\r\n>> >>> to use the read-only smaller entries while a larger one is being\r\n>\r\n> created.\r\n>>\r\n>> >>>\r\n>> >>>\r\n>> >>> On Sun, Oct 14, 2012 at 2:05 AM, Dmitry Vyukov\r\n>\r\n> <dvyukov@google.com>wrote:\r\n>>\r\n>> >>>\r\n>> >>>> I suggested to Robert to make the code work the way you describe.\r\n>> >>>\r\n>> >>>\r\n>> >>>\r\n>> >>>\r\n>> >>>  --\r\n>> >>> Michael T. Jones | Chief Technology Advocate  |\r\n>\r\n> mailto:mtj@google.com |  +1\r\n>>\r\n>> >>> 650-335-5765\r\n>> >>>\r\n>> >>>\r\n>> >>\r\n>> >\r\n>> >\r\n>> > --\r\n>> > Michael T. Jones\r\n>> > mailto:michael.jones@gmail.com\r\n>> > http://www.google.com/profiles/michael.jones\r\n>> >\r\n>\r\n>\r\n>\r\n> https://codereview.appspot.com/6643053/\r\n\r\n\r\n\r\n-- \r\nMichael T. Jones | Chief Technology Advocate  | mtj@google.com |  +1\r\n650-335-5765\r\n",
			"disapproval": false,
			"date": "2012-10-24 20:33:52.830020",
			"approval": false
		}
	],
	"owner_email": "gri@golang.org",
	"private": false,
	"base_url": "",
	"owner": "gri",
	"subject": "code review 6643053: math/big: more conservative use of lock for divisor table",
	"created": "2012-10-09 23:50:23.096380",
	"patchsets": [
		1,
		2001,
		3,
		6002,
		11001,
		5006,
		11002,
		3006,
		2005,
		14001,
		21001
	],
	"modified": "2012-10-24 19:03:51.385910",
	"closed": true,
	"issue": 6643053
}