{
	"description": "runtime: improved scheduler\nDistribute runnable queues, memory cache\nand cache of dead G's per processor.\nFaster non-blocking syscall enter/exit.\nMore conservative worker thread blocking/unblocking.",
	"cc": [
		"dave@cheney.net",
		"bradfitz@golang.org",
		"remyoudompheng@gmail.com",
		"rsc@golang.org",
		"golang-dev@googlegroups.com"
	],
	"reviewers": [],
	"messages": [
		{
			"sender": "dave@cheney.net",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Could you please hg upload this again,\n\n% hg clpatch 7314062\nabort: codereview issue 7314062 is out of date: patch and recent changes conflict (d2f4fe93c8d6->127f96912009)",
			"disapproval": false,
			"date": "2013-02-21 00:33:45.136850",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I guess I need to attach some benchmarks.",
			"disapproval": false,
			"date": "2013-02-27 20:50:58.283440",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "FTR patchset 21 is with network support",
			"disapproval": false,
			"date": "2013-02-21 14:46:03.707070",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello dave@cheney.net (cc: golang-dev@googlegroups.com),\n\nI'd like you to review this change to\nhttps://dvyukov%40google.com@code.google.com/p/go/",
			"disapproval": false,
			"date": "2013-02-27 20:46:50.353170",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/27 20:50:58, dvyukov wrote:\n> I guess I need to attach some benchmarks.\n\nUnfortunately I am currently on low-core laptop and can't ssh into anything serious. I will try to collect benchmark results tomorrow.",
			"disapproval": false,
			"date": "2013-02-27 21:10:46.893060",
			"approval": false
		},
		{
			"sender": "bradfitz@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Wed, Feb 27, 2013 at 1:10 PM, <dvyukov@google.com> wrote:\r\n\r\n> On 2013/02/27 20:50:58, dvyukov wrote:\r\n>\r\n>> I guess I need to attach some benchmarks.\r\n>>\r\n>\r\n> Unfortunately I am currently on low-core laptop and can't ssh into\r\n> anything serious. I will try to collect benchmark results tomorrow.\r\n\r\n\r\nHopefully the improved scheduler doesn't hurt performance on a low-core\r\nlaptop.  :-)\r\n",
			"disapproval": false,
			"date": "2013-02-27 23:22:31.664530",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "https://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c\nFile src/pkg/runtime/proc.c (right):\n\nhttps://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c#newcode948\nsrc/pkg/runtime/proc.c:948: // Tries to steal from other P's, get g from global queue, polls network connections.\npolls network connections !?",
			"disapproval": false,
			"date": "2013-02-28 06:26:38.451760",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Thursday, February 28, 2013, Brad Fitzpatrick wrote:\r\n\r\n>\r\n>\r\n> On Wed, Feb 27, 2013 at 1:10 PM, <dvyukov@google.com <javascript:_e({},\r\n> 'cvml', 'dvyukov@google.com');>> wrote:\r\n>\r\n>> On 2013/02/27 20:50:58, dvyukov wrote:\r\n>>\r\n>>> I guess I need to attach some benchmarks.\r\n>>>\r\n>>\r\n>> Unfortunately I am currently on low-core laptop and can't ssh into\r\n>> anything serious. I will try to collect benchmark results tomorrow.\r\n>\r\n>\r\n> Hopefully the improved scheduler doesn't hurt performance on a low-core\r\n> laptop.  :-)\r\n>\r\n>\r\nGood point\r\n",
			"disapproval": false,
			"date": "2013-02-28 09:04:54.545780",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Is it expected that proc.p is updated one day to match the new scheduler?",
			"disapproval": false,
			"date": "2013-02-28 23:23:49.886790",
			"approval": false
		},
		{
			"sender": "dave@cheney.net",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "> benchmark                       old ns/op    new ns/op    delta\r\n> BenchmarkSyscall                       56           80  +44.46%\r\n\r\nThis looks great, except for this number. Any idea why this number\r\nregressed for single GOMAXPROCS ?\r\n",
			"disapproval": false,
			"date": "2013-02-28 23:26:54.600280",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/03/01 00:07:20, dvyukov wrote:\n> linux/amd64, 2 x Intel Xeon E5-2690, 2.90GHz, 16 HT cores, 32 HW threads.\n> benchmark                        old ns/op    new ns/op    delta\n> BenchmarkSyscall                        21           30  +39.17%\n\nIt seems to be just some issues with code generation in 6c.\n\nJust caching g and m as:\n\n\tG *gp;\n\tM *mp;\n\n\tmp = m;\n\tgp = g;\nand then doing everything with gp and mp:\n\tgp->gcsp = gp->sched.sp;\n\tgp->gcstack = gp->stackbase;\n\tgp->gcguard = gp->stackguard;\n\tgp->status = Gsyscall;\n\nreduces exec time from 30.2 to 26.2 ns/op.\n\nThen replacing:\n        -runtime\u00b7atomicstore(&mp->p->status, Psyscall);\n        +mp->p->status = Psyscall;\n\nreduces exec time to 17.7ns.\n\nWe can do some of that nanosecond-squeezing after submitting the patch.\nDave, you asked whether it makes sense to add ATOMIC_LOAD/ATOMIC_STORE/ATOMIC_CAS intrinsics to gc similar to PREFETCH. I think it can have some impact with the new scheduler.",
			"disapproval": false,
			"date": "2013-03-01 00:45:46.173510",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Thursday, February 28, 2013, wrote:\r\n\r\n>\r\n> https://codereview.appspot.**com/7314062/diff/62004/src/**\r\n> pkg/runtime/proc.c<https://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c>\r\n> File src/pkg/runtime/proc.c (right):\r\n>\r\n> https://codereview.appspot.**com/7314062/diff/62004/src/**\r\n> pkg/runtime/proc.c#newcode948<https://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c#newcode948>\r\n> src/pkg/runtime/proc.c:948: // Tries to steal from other P's, get g from\r\n> global queue, polls network connections.\r\n> polls network connections !?\r\n>\r\n>\r\n\r\nThat's why I don't like comments -- they does not stop to compile when\r\nbecome incorrect :)\r\nPolling of network connections is Phase II, it will be submitted separately.\r\n",
			"disapproval": false,
			"date": "2013-02-28 09:06:41.248280",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/28 23:26:54, dfc wrote:\n> > benchmark                       old ns/op    new ns/op    delta\n> > BenchmarkSyscall                       56           80  +44.46%\n> \n> This looks great, except for this number. Any idea why this number\n> regressed for single GOMAXPROCS ?\n\nThere is also the regression in BenchmarkTCPPersistent. It's intended to be fixed by integrated network poller.",
			"disapproval": false,
			"date": "2013-02-28 23:36:11.414170",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/28 23:23:49, remyoudompheng wrote:\n> Is it expected that proc.p is updated one day to match the new scheduler?\n\nI have no such plans. Perhaps I need to delete proc.p with this patch.",
			"disapproval": false,
			"date": "2013-02-28 23:28:27.631000",
			"approval": false
		},
		{
			"sender": "dave@cheney.net",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "> Then replacing:\r\n>         -runtime\u00b7atomicstore(&mp->p->status, Psyscall);\r\n>         +mp->p->status = Psyscall;\r\n>\r\n> reduces exec time to 17.7ns.\r\n\r\nNice catch. I'd vote for making that change to the source (with a\r\ncomment of course), and raising a bug against cmd/6c (any others) for\r\nthe code generation suckage.\r\n\r\n> We can do some of that nanosecond-squeezing after submitting the patch.\r\n> Dave, you asked whether it makes sense to add\r\n> ATOMIC_LOAD/ATOMIC_STORE/ATOMIC_CAS intrinsics to gc similar to\r\n> PREFETCH. I think it can have some impact with the new scheduler.\r\n\r\nI agree, I would like to see those intrinsics added post Go 1.1. If\r\nyou wanted to open an issue as a reminder, I'd +1 that.\r\n",
			"disapproval": false,
			"date": "2013-03-01 00:50:41.232350",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "This broke FreeBSD and Windows, which assumed that newosproc would only\r\never be called with fn == mstart (probably on my suggestion).\r\nCL 7443046, just submitted, should fix those.\r\n\r\nThis broke Linux/ARM: the builds time out. I don't know why yet. It does\r\nnot appear to be the same reason.\r\n\r\nRuss\r\n",
			"disapproval": false,
			"date": "2013-03-01 13:30:56.487410",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "linux/amd64, 2 x Intel Xeon E5-2690, 2.90GHz, 16 HT cores, 32 HW threads.\n\nGOMAXPROCS=1 time go test -short std\nold#1 0:06.70elapsed\nold#2 0:06.97elapsed\nnew#1 0:06.91elapsed\nnew#2 0:07.01elapsed\n\nGOMAXPROCS=2 time go test -short std\nold#1 0:06.73elapsed\nold#2 0:06.77elapsed\nnew#1 0:06.89elapsed\nnew#2 0:06.94elapsed\n\nGOMAXPROCS=16 time go test -short std\nold#1 0:06.90elapsed\nold#2 0:06.87elapsed\nnew#1 0:06.93elapsed\nnew#2 0:06.92elapsed\n\nGOMAXPROCS=1 time ./threadring -n=10000000\nold: 1.84user 0.00system 0:01.85elapsed 99%CPU\nnew: 1.45user 0.00system 0:01.45elapsed 99%CPU\n\nGOMAXPROCS=2 time ./threadring -n=10000000\nold: 26.90user 57.75system 1:25.04elapsed 99%CPU\nnew: 7.97user 4.18system 0:07.18elapsed 169%CPU\n\nGOMAXPROCS=2 time ./threadring -n=10000000\nold: 4.82user 24.54system 0:29.17elapsed 100%CPU\nnew: 8.68user 3.33system 0:06.35elapsed 189%CPU\n\nbenchmark              old ns/op    new ns/op    delta\nBenchmarkMatmult               7            6   -2.14%\nBenchmarkMatmult-2             6            3  -47.25%\nBenchmarkMatmult-4             6            2  -51.16%\nBenchmarkMatmult-8             7            1  -85.51%\nBenchmarkMatmult-16            6            1  -81.04%\nBenchmarkMatmult-32            6            1  -83.44%\n\nbenchmark                        old ns/op    new ns/op    delta\nBenchmarkSyscall                        21           30  +39.17%\nBenchmarkSyscall-2                      85           14  -83.08%\nBenchmarkSyscall-4                      90            9  -89.15%\nBenchmarkSyscall-8                      94            7  -91.80%\nBenchmarkSyscall-16                     92            7  -91.49%\nBenchmarkSyscall-32                     81            9  -88.85%\nBenchmarkSyscallWork                   224          207   -7.59%\nBenchmarkSyscallWork-2                 131          104  -20.61%\nBenchmarkSyscallWork-4                 117          108   -7.69%\nBenchmarkSyscallWork-8                 168           80  -52.14%\nBenchmarkSyscallWork-16                173          104  -39.88%\nBenchmarkSyscallWork-32                115          106   -7.83%\nBenchmarkSyscallExcess                2635           27  -98.96%\nBenchmarkSyscallExcess-2              1305           14  -98.90%\nBenchmarkSyscallExcess-4               581            7  -98.68%\nBenchmarkSyscallExcess-8               410            4  -98.94%\nBenchmarkSyscallExcess-16              370            2  -99.33%\nBenchmarkSyscallExcess-32               84            2  -97.55%\nBenchmarkSyscallExcessWork            2551          217  -91.49%\nBenchmarkSyscallExcessWork-2          1360          108  -92.06%\nBenchmarkSyscallExcessWork-4           479           55  -88.52%\nBenchmarkSyscallExcessWork-8           572           29  -94.91%\nBenchmarkSyscallExcessWork-16          368           15  -95.87%\nBenchmarkSyscallExcessWork-32          129            9  -92.88%\n\nbenchmark                               old ns/op    new ns/op    delta\nBenchmarkCreateGoroutines                     132           91  -30.76%\nBenchmarkCreateGoroutines-2                  6043          371  -93.86%\nBenchmarkCreateGoroutines-4                  2689          341  -87.32%\nBenchmarkCreateGoroutines-8                  2597          354  -86.37%\nBenchmarkCreateGoroutines-16                 2649          290  -89.05%\nBenchmarkCreateGoroutines-32                 2649          249  -90.60%\nBenchmarkCreateGoroutinesParallel             132           93  -28.94%\nBenchmarkCreateGoroutinesParallel-2           620          183  -70.48%\nBenchmarkCreateGoroutinesParallel-4          1128          134  -88.12%\nBenchmarkCreateGoroutinesParallel-8          1247          158  -87.33%\nBenchmarkCreateGoroutinesParallel-16         1051          135  -87.16%\nBenchmarkCreateGoroutinesParallel-32         1035          101  -90.24%\n\nbenchmark                           old ns/op    new ns/op    delta\nBenchmarkTCPOneShot                    193051       168129  -12.91%\nBenchmarkTCPOneShot-2                   63436        92020  +45.06%\nBenchmarkTCPOneShot-4                   34853        52074  +49.41%\nBenchmarkTCPOneShot-8                   21967        26320  +19.82%\nBenchmarkTCPOneShot-16                  16690        12575  -24.66%\nBenchmarkTCPOneShot-32                  16516        13397  -18.88%\nBenchmarkTCPOneShotTimeout             197609       158659  -19.71%\nBenchmarkTCPOneShotTimeout-2            59513        91054  +53.00%\nBenchmarkTCPOneShotTimeout-4            35127        51983  +47.99%\nBenchmarkTCPOneShotTimeout-8            21731        25853  +18.97%\nBenchmarkTCPOneShotTimeout-16           16486        12543  -23.92%\nBenchmarkTCPOneShotTimeout-32           16505        13502  -18.19%\nBenchmarkTCPPersistent                  29966        77936  +160.08%\nBenchmarkTCPPersistent-2                23870        56330  +135.99%\nBenchmarkTCPPersistent-4                15390        28349  +84.20%\nBenchmarkTCPPersistent-8                18327        12450  -32.07%\nBenchmarkTCPPersistent-16               17424         2271  -86.97%\nBenchmarkTCPPersistent-32                7783         1777  -77.17%\nBenchmarkTCPPersistentTimeout           88653        78359  -11.61%\nBenchmarkTCPPersistentTimeout-2         26396        57312  +117.12%\nBenchmarkTCPPersistentTimeout-4         15724        26291  +67.20%\nBenchmarkTCPPersistentTimeout-8         18375        16064  -12.58%\nBenchmarkTCPPersistentTimeout-16        17443         2461  -85.89%\nBenchmarkTCPPersistentTimeout-32         7777         1840  -76.34%",
			"disapproval": false,
			"date": "2013-03-01 00:07:20.991160",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/28 06:26:38, remyoudompheng wrote:\n> https://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c\n> File src/pkg/runtime/proc.c (right):\n> \n> https://codereview.appspot.com/7314062/diff/62004/src/pkg/runtime/proc.c#newcode948\n> src/pkg/runtime/proc.c:948: // Tries to steal from other P's, get g from global\n> queue, polls network connections.\n> polls network connections !?\n\nDone.",
			"disapproval": false,
			"date": "2013-02-28 23:05:08.204240",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/27 23:22:31, bradfitz wrote:\n> On Wed, Feb 27, 2013 at 1:10 PM, <mailto:dvyukov@google.com> wrote:\n> \n> > On 2013/02/27 20:50:58, dvyukov wrote:\n> >\n> >> I guess I need to attach some benchmarks.\n> >>\n> >\n> > Unfortunately I am currently on low-core laptop and can't ssh into\n> > anything serious. I will try to collect benchmark results tomorrow.\n> \n> \n> Hopefully the improved scheduler doesn't hurt performance on a low-core\n> laptop.  :-)\n\nHere are some numbers on darwin/amd64, Intel Core 2 Duo 2.13 GHz, 2 cores:\n\nGOMAXPROCS=1 time go test -short std\nold:\n#1 real 81.743s\n#2 real 80.896s\nnew:\n#1 real 81.278s\n#2 real 81.319s\n\nGOMAXPROCS=2 time go test -short std\nold:\n#1 real 85.61s\n#2 real 104.93s\nnew:\n#1 real 81.36s\n#2 real 82.51s\n\nGOMAXPROCS=1 time ./threadring -n=2000000\nold:\nreal\t0m0.907s\nuser\t0m0.894s\nsys\t0m0.007s\nnew:\nreal\t0m0.763s\nuser\t0m0.753s\nsys\t0m0.006s\n\nGOMAXPROCS=2 time ./threadring -n=2000000\nold:\nreal\t0m6.070s\nuser\t0m2.650s\nsys\t0m4.851s\nnew:\nreal\t0m2.090s\nuser\t0m2.759s\nsys\t0m0.735s\n\nbenchmark             old ns/op    new ns/op    delta\nBenchmarkMatmult             26           25   -5.28%\nBenchmarkMatmult-2           10            9  -12.78%\n\nbenchmark                       old ns/op    new ns/op    delta\nBenchmarkSyscall                       56           80  +44.46%\nBenchmarkSyscall-2                     57           43  -24.13%\nBenchmarkSyscallWork                  635          615   -3.15%\nBenchmarkSyscallWork-2                315          302   -4.13%\nBenchmarkSyscallExcess               2698           80  -97.02%\nBenchmarkSyscallExcess-2             1192           42  -96.43%\nBenchmarkSyscallExcessWork           2832          596  -78.95%\nBenchmarkSyscallExcessWork-2         1966          302  -84.64%\n\nbenchmark                              old ns/op    new ns/op    delta\nBenchmarkCreateGoroutines                    355          266  -25.07%\nBenchmarkCreateGoroutines-2                 2314          701  -69.71%\nBenchmarkCreateGoroutinesParallel            358          289  -19.27%\nBenchmarkCreateGoroutinesParallel-2          439          163  -62.87%\n\nbenchmark                          old ns/op    new ns/op    delta\nBenchmarkTCPOneShot                   373801       197980  -47.04%\nBenchmarkTCPOneShot-2                 367226       334230   -8.99%\nBenchmarkTCPOneShotTimeout            388088       201246  -48.14%\nBenchmarkTCPOneShotTimeout-2          438246       348140  -20.56%\nBenchmarkTCPPersistent                 64992        79598  +22.47%\nBenchmarkTCPPersistent-2               58297        41134  -29.44%\nBenchmarkTCPPersistentTimeout          65471        77702  +18.68%\nBenchmarkTCPPersistentTimeout-2        57122        42875  -24.94%",
			"disapproval": false,
			"date": "2013-02-28 23:09:46.648250",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "crossing fingers and submitting for soaking %)",
			"disapproval": false,
			"date": "2013-03-01 11:47:42.281790",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/28 23:26:54, dfc wrote:\n> > benchmark                       old ns/op    new ns/op    delta\n> > BenchmarkSyscall                       56           80  +44.46%\n> \n> This looks great, except for this number. Any idea why this number\n> regressed for single GOMAXPROCS ?\n\nI don't know how to profile on darwin. I am currently benchmarking on linux, if it has the same regression I will profile.",
			"disapproval": false,
			"date": "2013-02-28 23:29:42.427530",
			"approval": false
		},
		{
			"sender": "bradfitz@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Thu, Feb 28, 2013 at 4:07 PM, <dvyukov@google.com> wrote:\r\n\r\n> linux/amd64, 2 x Intel Xeon E5-2690, 2.90GHz, 16 HT cores, 32 HW\r\n> threads.\r\n>\r\n> GOMAXPROCS=1 time ./threadring -n=10000000\r\n> old: 1.84user 0.00system 0:01.85elapsed 99%CPU\r\n> new: 1.45user 0.00system 0:01.45elapsed 99%CPU\r\n>\r\n> GOMAXPROCS=2 time ./threadring -n=10000000\r\n> old: 26.90user 57.75system 1:25.04elapsed 99%CPU\r\n> new: 7.97user 4.18system 0:07.18elapsed 169%CPU\r\n>\r\n> GOMAXPROCS=2 time ./threadring -n=10000000\r\n> old: 4.82user 24.54system 0:29.17elapsed 100%CPU\r\n> new: 8.68user 3.33system 0:06.35elapsed 189%CPU\r\n\r\n\r\nIs that last one correct?\r\n",
			"disapproval": false,
			"date": "2013-03-01 00:12:38.296770",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "LGTM\n\nThanks very much for this work.\n\nI patched this into my client and tested that all.bash passes. I also printed proc.c (without diffs) and read it all, even the unchanged parts. It looks good. \n\nAs long as it isn't going to break the build, I think we should submit this soon, so that it can soak. I realize you probably have some tweaks planned still, but it will be easier to review them as deltas than to keep updating this CL.\n\nMy only substantial concern is some of the locking. At least nmspinning, runqsize, and sysmonwait are accessed both directly and via atomic operations, sometimes in a double-checked locking pattern and sometimes just using an ordinary read where one might expect an atomic read. Is this safe even on multiprocessor ARM? I assume so - you're the locking expert - but I just wanted to double-check, as it were.\n\nIf there are places where you think an atomic is warranted but you have changed it to be non-atomic purely for performance, please mark those with comments that say something like:\n    // TODO: fast atomic\nand those will serve as markers to revisit if we put atomic intrinsics into 6c.\n\nMinor comments below.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c\nFile src/pkg/runtime/proc.c (right):\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode28\nsrc/pkg/runtime/proc.c:28: M*\tmhead;\t // m's waiting for work\nYou left this name unchanged, but given pidle and npidle below, I suggest renaming mhead, mwait to midle, mpidle. Your decision.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode54\nsrc/pkg/runtime/proc.c:54: enum { maxgomaxprocs = 1<<8 };\nSince this is C and not Go, constants should begin with an upper case letter.\nMaxGomaxprocs perhaps.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode399\nsrc/pkg/runtime/proc.c:399: if(p->runqhead == p->runqtail) {\nCan you please add a comment explaining why finding a p without a run queue means the remainder of the idle p's have no run queue either?\nSomething like:\n\n// Stopped p's are at beginning of list.\n// Once we reach a p without a run queue, the rest don't have one either.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode487\nsrc/pkg/runtime/proc.c:487: // Allocate a new m unassociated with any thread.\nadd\n// Can use p for allocation context if needed.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1162\nsrc/pkg/runtime/proc.c:1162: g->gcsp = g->sched.sp;\nCarl has a pending change that adds g->gcpc and sets it here and in entersyscallblock, but we're still trying to track down a linux/386 problem in that CL, so it probably won't land soon.\n\nPlease pick up those changes to entersyscall and entersyscallblock, from\nhttps://codereview.appspot.com/7301062/diff/24002/src/pkg/runtime/proc.c\nso that Carl doesn't need to reapply them at the inevitable merge conflict.\n\nThanks.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1209\nsrc/pkg/runtime/proc.c:1209: g->gcsp = g->sched.sp;\nThis part needs a gcpc too.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1241\nsrc/pkg/runtime/proc.c:1241: s = m->p ? m->p->status : Pidle;\nIn general please try to avoid ? :. Writing the if/else is longer but in the long term usually more readable.\n\nIn this specific case, I don't think you need the condition at all: I don't see where s is used other than in the condition on the next line, which can become:\n\nif(m->p && runtime.cas(&m->p->status, Psyscall, Prunning)) {\n\n(with an && m->p->status == Psyscall in the middle if you think it's important)\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1250\nsrc/pkg/runtime/proc.c:1250: g->gcstack = (uintptr)nil;\nPlease clear gcsp here too.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1278\nsrc/pkg/runtime/proc.c:1278: g->gcstack = (uintptr)nil;\nHere too.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1514\nsrc/pkg/runtime/proc.c:1514: // delete when scheduler is even stronger\n:-)\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1624\nsrc/pkg/runtime/proc.c:1624: for(gp = runtime\u00b7allg; gp; gp = gp->alllink) {\nI did not realize that runtime.NumGoroutine was O(n). Perhaps it is worth a TODO to make it O(1). This is kind of embarrassing (my fault not yours).\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1747\nsrc/pkg/runtime/proc.c:1747: for(i = 1; runtime\u00b7sched.runqhead; i++) {\nI am a little confused about why i starts at 1 here. Is there a reason to skip 0? If so, it's worth a comment; if not, please i = 0.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1820\nsrc/pkg/runtime/proc.c:1820: inclocked(int32 v) {\n{ on next line.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode2078\nsrc/pkg/runtime/proc.c:2078: // TODO(dvyukov): consider using fixed-size array\nsgtm",
			"disapproval": false,
			"date": "2013-03-01 05:11:43.512820",
			"approval": true
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/03/01 00:12:38, bradfitz wrote:\n> On Thu, Feb 28, 2013 at 4:07 PM, <mailto:dvyukov@google.com> wrote:\n> \n> > linux/amd64, 2 x Intel Xeon E5-2690, 2.90GHz, 16 HT cores, 32 HW\n> > threads.\n> >\n> > GOMAXPROCS=1 time ./threadring -n=10000000\n> > old: 1.84user 0.00system 0:01.85elapsed 99%CPU\n> > new: 1.45user 0.00system 0:01.45elapsed 99%CPU\n> >\n> > GOMAXPROCS=2 time ./threadring -n=10000000\n> > old: 26.90user 57.75system 1:25.04elapsed 99%CPU\n> > new: 7.97user 4.18system 0:07.18elapsed 169%CPU\n> >\n> > GOMAXPROCS=2 time ./threadring -n=10000000\n> > old: 4.82user 24.54system 0:29.17elapsed 100%CPU\n> > new: 8.68user 3.33system 0:06.35elapsed 189%CPU\n> \n> \n> Is that last one correct?\n\nSomebody is actually carefully reading it! :)\nYes, that was GOMAXPROCS=4. There are some non-linear effects for both old and new.",
			"disapproval": false,
			"date": "2013-03-01 00:19:57.034640",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Fri, Mar 1, 2013 at 2:50 AM, Dave Cheney <dave@cheney.net> wrote:\r\n\r\n> > Then replacing:\r\n> >         -runtime\u00b7atomicstore(&mp->p->status, Psyscall);\r\n> >         +mp->p->status = Psyscall;\r\n> >\r\n> > reduces exec time to 17.7ns.\r\n>\r\n> Nice catch. I'd vote for making that change to the source (with a\r\n> comment of course), and raising a bug against cmd/6c (any others) for\r\n> the code generation suckage.\r\n>\r\n> > We can do some of that nanosecond-squeezing after submitting the patch.\r\n> > Dave, you asked whether it makes sense to add\r\n> > ATOMIC_LOAD/ATOMIC_STORE/ATOMIC_CAS intrinsics to gc similar to\r\n> > PREFETCH. I think it can have some impact with the new scheduler.\r\n>\r\n> I agree, I would like to see those intrinsics added post Go 1.1. If\r\n> you wanted to open an issue as a reminder, I'd +1 that.\r\n>\r\n\r\n\r\nSorry, the effect comes mostly from XCHG instruction.\r\nWith atomicstore - 27.6ns\r\nWith atomicstore with MOVL instead of XCHGL - 17.2ns\r\nWith plain assignment - 15.6ns\r\n\r\nBut I still think it would be useful, it can cut few ns here and there\r\n(e.g. runtime.lock/unlock).\r\n",
			"disapproval": false,
			"date": "2013-03-01 01:18:00.122740",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/02/28 23:23:49, remyoudompheng wrote:\n> Is it expected that proc.p is updated one day to match the new scheduler?\n\nIt would be nice, but I won't make it a requirement. The tricky part that proc.p was meant to verify is the unlocked fast path in entersyscall/exitsyscall. That mostly goes away in this CL, left instead to the sysmon thread. The surrounding code is a bit more complex, but at least the system call path is easier to understand.",
			"disapproval": false,
			"date": "2013-03-01 05:14:49.728440",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2013/03/01 05:11:43, rsc wrote:\n> LGTM\n> \n> Thanks very much for this work.\n> \n> I patched this into my client and tested that all.bash passes. I also printed\n> proc.c (without diffs) and read it all, even the unchanged parts. It looks good.\n> \n> \n> As long as it isn't going to break the build, I think we should submit this\n> soon, so that it can soak. I realize you probably have some tweaks planned\n> still, but it will be easier to review them as deltas than to keep updating this\n> CL.\n\nYeah, it's a pain to work with this CL.\n\n\n> My only substantial concern is some of the locking. At least nmspinning,\n> runqsize, and sysmonwait are accessed both directly and via atomic operations,\n> sometimes in a double-checked locking pattern and sometimes just using an\n> ordinary read where one might expect an atomic read. Is this safe even on\n> multiprocessor ARM? I assume so - you're the locking expert - but I just wanted\n> to double-check, as it were.\n> \n> If there are places where you think an atomic is warranted but you have changed\n> it to be non-atomic purely for performance, please mark those with comments that\n> say something like:\n>     // TODO: fast atomic\n> and those will serve as markers to revisit if we put atomic intrinsics into 6c.\n\n\nYes, you are right. Some of the accesses must be atomic and I did not put atomicload/atomicstore because of performance concerns. I will add the TODOs.",
			"disapproval": false,
			"date": "2013-03-01 09:14:53.011860",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "FTR, patch set 36 is re-sync.",
			"disapproval": false,
			"date": "2013-03-01 09:15:42.051590",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "https://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c\nFile src/pkg/runtime/proc.c (right):\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode28\nsrc/pkg/runtime/proc.c:28: M*\tmhead;\t // m's waiting for work\nOn 2013/03/01 05:11:43, rsc wrote:\n> You left this name unchanged, but given pidle and npidle below, I suggest\n> renaming mhead, mwait to midle, mpidle. Your decision.\n\nrenamed to midle and nmidle.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode54\nsrc/pkg/runtime/proc.c:54: enum { maxgomaxprocs = 1<<8 };\nOn 2013/03/01 05:11:43, rsc wrote:\n> Since this is C and not Go, constants should begin with an upper case letter.\n> MaxGomaxprocs perhaps.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode399\nsrc/pkg/runtime/proc.c:399: if(p->runqhead == p->runqtail) {\nOn 2013/03/01 05:11:43, rsc wrote:\n> Can you please add a comment explaining why finding a p without a run queue\n> means the remainder of the idle p's have no run queue either?\n> Something like:\n> \n> // Stopped p's are at beginning of list.\n> // Once we reach a p without a run queue, the rest don't have one either.\n\nDone.\nprocresize() puts p's with work at the beginning of the list.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode487\nsrc/pkg/runtime/proc.c:487: // Allocate a new m unassociated with any thread.\nOn 2013/03/01 05:11:43, rsc wrote:\n> add\n> // Can use p for allocation context if needed.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1162\nsrc/pkg/runtime/proc.c:1162: g->gcsp = g->sched.sp;\nOn 2013/03/01 05:11:43, rsc wrote:\n> Carl has a pending change that adds g->gcpc and sets it here and in\n> entersyscallblock, but we're still trying to track down a linux/386 problem in\n> that CL, so it probably won't land soon.\n> \n> Please pick up those changes to entersyscall and entersyscallblock, from\n> https://codereview.appspot.com/7301062/diff/24002/src/pkg/runtime/proc.c\n> so that Carl doesn't need to reapply them at the inevitable merge conflict.\n> \n> Thanks.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1209\nsrc/pkg/runtime/proc.c:1209: g->gcsp = g->sched.sp;\nOn 2013/03/01 05:11:43, rsc wrote:\n> This part needs a gcpc too.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1241\nsrc/pkg/runtime/proc.c:1241: s = m->p ? m->p->status : Pidle;\nOn 2013/03/01 05:11:43, rsc wrote:\n> In general please try to avoid ? :. Writing the if/else is longer but in the\n> long term usually more readable.\n> \n> In this specific case, I don't think you need the condition at all: I don't see\n> where s is used other than in the condition on the next line, which can become:\n> \n> if(m->p && runtime.cas(&m->p->status, Psyscall, Prunning)) {\n> \n> (with an && m->p->status == Psyscall in the middle if you think it's important)\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1250\nsrc/pkg/runtime/proc.c:1250: g->gcstack = (uintptr)nil;\nOn 2013/03/01 05:11:43, rsc wrote:\n> Please clear gcsp here too.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1278\nsrc/pkg/runtime/proc.c:1278: g->gcstack = (uintptr)nil;\nOn 2013/03/01 05:11:43, rsc wrote:\n> Here too.\n\nDone.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1624\nsrc/pkg/runtime/proc.c:1624: for(gp = runtime\u00b7allg; gp; gp = gp->alllink) {\nOn 2013/03/01 05:11:43, rsc wrote:\n> I did not realize that runtime.NumGoroutine was O(n). Perhaps it is worth a TODO\n> to make it O(1). This is kind of embarrassing (my fault not yours).\n\nYes, it's O(N). I do not want to increment/decrement atomic counter in newproc/goexit, they can proceed almost P-local otherwise.\nIf it's important we can have per-P counters, then aggregation will be much faster.\nAdding the comment.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1747\nsrc/pkg/runtime/proc.c:1747: for(i = 1; runtime\u00b7sched.runqhead; i++) {\nOn 2013/03/01 05:11:43, rsc wrote:\n> I am a little confused about why i starts at 1 here. Is there a reason to skip\n> 0? If so, it's worth a comment; if not, please i = 0.\n\nDone.\nYes, there is a reason.\n\nhttps://codereview.appspot.com/7314062/diff/76001/src/pkg/runtime/proc.c#newcode1820\nsrc/pkg/runtime/proc.c:1820: inclocked(int32 v) {\nOn 2013/03/01 05:11:43, rsc wrote:\n> { on next line.\n\nDone.",
			"disapproval": false,
			"date": "2013-03-01 11:34:28.217740",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"dvyukov@google.com",
				"dave@cheney.net",
				"bradfitz@golang.org",
				"remyoudompheng@gmail.com",
				"rsc@golang.org",
				"golang-dev@googlegroups.com",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "*** Submitted as https://code.google.com/p/go/source/detail?r=231af8ac63aa ***\n\nruntime: improved scheduler\nDistribute runnable queues, memory cache\nand cache of dead G's per processor.\nFaster non-blocking syscall enter/exit.\nMore conservative worker thread blocking/unblocking.\n\nR=dave, bradfitz, remyoudompheng, rsc\nCC=golang-dev\nhttps://codereview.appspot.com/7314062",
			"disapproval": false,
			"date": "2013-03-01 11:49:39.748200",
			"approval": false
		},
		{
			"sender": "rsc@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Windows is still broken. I know what's wrong but I want to fix it by\r\ncleaning up some of the internals a bit. CL in an hour or so.\r\n",
			"disapproval": false,
			"date": "2013-03-01 16:07:42.667300",
			"approval": false
		},
		{
			"sender": "dvyukov@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "misc/cgo/test/TestCthread sometimes hangs on darwin with GOMAXPROCS=42, I\r\nam working on this.\r\n",
			"disapproval": false,
			"date": "2013-03-01 16:28:44.958600",
			"approval": false
		}
	],
	"owner_email": "dvyukov@google.com",
	"private": false,
	"base_url": "",
	"owner": "dvyukov",
	"subject": "code review 7314062: runtime: improved scheduler",
	"created": "2013-02-08 13:58:57.477580",
	"patchsets": [
		1,
		2001,
		7001,
		10001,
		13001,
		15012,
		17001,
		20001,
		23001,
		12012,
		26001,
		14,
		14012,
		15024,
		25012,
		36001,
		39001,
		41001,
		46001,
		44002,
		53001,
		55001,
		42010,
		59001,
		61001,
		51002,
		38013,
		57006,
		64002,
		57007,
		46002,
		47015,
		68001,
		62004,
		76001,
		88001,
		89003,
		90002,
		95001
	],
	"modified": "2013-03-01 14:45:47.825660",
	"closed": true,
	"issue": 7314062
}