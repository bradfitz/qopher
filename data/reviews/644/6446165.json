{
	"description": "math/big: unroll loops a bit in amd64 assembly routines.\n\nProcessing 4 words at a time reduces the amount of instructions\nneeded to save and restore the carry flag, among other things.\n\nBenchmarks on a Core 2 Quad Q8200@2.33GHz\n\nbenchmark             old ns/op    new ns/op    delta\nBenchmarkAdd_1w              50           48   -2.40%\nBenchmarkAdd_2w              50           52   +4.55%\nBenchmarkAdd_5w              55           59   +5.73%\nBenchmarkAdd_100kb         4285         2528  -41.00%\nBenchmarkAdd_1Mb          44307        24145  -45.51%\nBenchmarkAdd_5Mb         325697       289706  -11.05%\nBenchmarkAdd_10Mb       1137018      1106273   -2.70%\nBenchmarkMul_1w              52           52   -0.76%\nBenchmarkMul_2w             117          117   +0.00%\nBenchmarkMul_5w             241          228   -5.39%\nBenchmarkMul_1kb           1101          940  -14.62%\nBenchmarkMul_10kb         59019        47135  -20.14%\nBenchmarkMul_50kb        829171       643858  -22.35%\nBenchmarkMul_100kb      2563856      1999235  -22.02%\nBenchmarkMul_1Mb      105886450     83408800  -21.23%\nBenchmarkMul_5Mb     1285270000   1005876000  -21.74%\nBenchmarkMul_10Mb    3869718000   3029543000  -21.71%",
	"cc": [
		"golang-dev@googlegroups.com",
		"remy@archlinux.org"
	],
	"reviewers": [
		"gri@golang.org",
		"cswenson@google.com",
		"nigeltao@golang.org",
		"r@golang.org",
		"iant@google.com"
	],
	"messages": [
		{
			"sender": "cswenson@google.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"golang-dev@googlegroups.org",
				"cswenson@google.com",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2012/08/21 19:03:31, remyoudompheng wrote:\n> Hello mailto:gri@golang.org, mailto:golang-dev@googlegroups.org (cc:\n> mailto:golang-dev@googlegroups.com, mailto:remy@archlinux.org),\n> \n> Please take another look.\n\nI saw this patch and took a quick look. I spotted a couple of potential improvements.\n\nThough, when we are talking about 1Mb+ numbers for multiplication, we should really look into Toom-Cook multiplication, or even an FFT-based multiply.",
			"disapproval": false,
			"date": "2012-08-21 21:42:11.746320",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "I will look at this a bit later (today or tomorrow). In the meantime could\r\nyou add benchmarks showing that this doesn't slow down small numbers?\r\nThanks.\r\n- gri\r\n\r\n\r\nOn Tue, Aug 21, 2012 at 10:55 AM, <remyoudompheng@gmail.com> wrote:\r\n\r\n> Reviewers: gri, golang-dev_googlegroups.org,\r\n>\r\n> Message:\r\n> Hello gri@golang.org, golang-dev@googlegroups.org (cc:\r\n> golang-dev@googlegroups.com, remy@archlinux.org),\r\n>\r\n> I'd like you to review this change to\r\n> https://go.googlecode.com/hg/\r\n>\r\n>\r\n> Description:\r\n> math/big: unroll loops a bit in amd64 assembly routines.\r\n>\r\n> Processing 4 words at a time reduces the amount of instructions\r\n> needed to save and restore the carry flag, among other things.\r\n>\r\n> Benchmarks on a Core 2 Quad Q8200@2.33GHz\r\n>\r\n> benchmark             old ns/op    new ns/op    delta\r\n> BenchmarkAdd_100kb         4400         2517  -42.80%\r\n> BenchmarkAdd_1Mb          43965        24363  -44.59%\r\n> BenchmarkAdd_5Mb         335207       264941  -20.96%\r\n> BenchmarkAdd_10Mb       1148330      1158397   +0.88%\r\n> BenchmarkMul_1kb           1189          940  -20.94%\r\n> BenchmarkMul_10kb         58555        46842  -20.00%\r\n> BenchmarkMul_50kb        825427       642377  -22.18%\r\n> BenchmarkMul_100kb      2555077      1983290  -22.38%\r\n> BenchmarkMul_1Mb      105479750     82940000  -21.37%\r\n> BenchmarkMul_5Mb     1284871000   1004868000  -21.79%\r\n> BenchmarkMul_10Mb    3875074000   3038164000  -21.60%\r\n>\r\n> Please review this at http://codereview.appspot.com/**6446165/<http://codereview.appspot.com/6446165/>\r\n>\r\n> Affected files:\r\n>   M src/pkg/math/big/arith_amd64.s\r\n>   M src/pkg/math/big/nat_test.go\r\n>\r\n>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-08-21 18:53:59.672900",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"golang-dev@googlegroups.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello gri@golang.org, golang-dev@googlegroups.org (cc: golang-dev@googlegroups.com, remy@archlinux.org),\n\nPlease take another look.",
			"disapproval": false,
			"date": "2012-08-21 19:03:31.054980",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"golang-dev@googlegroups.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Hello gri@golang.org, golang-dev@googlegroups.org (cc: golang-dev@googlegroups.com, remy@archlinux.org),\n\nI'd like you to review this change to\nhttps://go.googlecode.com/hg/",
			"disapproval": false,
			"date": "2012-08-21 17:55:46.965070",
			"approval": false
		},
		{
			"sender": "cswenson@google.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"golang-dev@googlegroups.org",
				"cswenson@google.com",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode38\nsrc/pkg/math/big/arith_amd64.s:38: MOVQ $0, BX\t\t// i = 0\nThis instruction is 7 bytes long, whereas XOR BX, BX is only 3. Ditto for the following instruction.\n\nAlthough this might cause the pipeline to stall, I believe that the instruction size difference should make up for it.\n\nIf the pipeline stall is too much, move MOVQ $0, BX to before the shifts, and change the latter to MOVQ BX, DX.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode46\nsrc/pkg/math/big/arith_amd64.s:46: RCRQ $1, DX\nMove this rotate to before the MOVQs to ease the pipeline a little? On most architectures the processor should reorder this already, but some (like, say, Atom) it could cause a delay. The carry flag should be preserved through the MOVQs.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode51\nsrc/pkg/math/big/arith_amd64.s:51: RCLQ $1, DX\nDitto above.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode56\nsrc/pkg/math/big/arith_amd64.s:56: ADDL $4, BX\t\t// i+=4\nI feel like we should move $4 into a register (perhaps AX) to save the byte here.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode85\nsrc/pkg/math/big/arith_amd64.s:85: MOVQ $0, BX\t\t// i = 0\nDitto previous comments about instruction size.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode93\nsrc/pkg/math/big/arith_amd64.s:93: RCRQ $1, DX\nSee previous comments about moving the RCRQ/RCLQ.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode103\nsrc/pkg/math/big/arith_amd64.s:103: ADDL $4, BX\t\t// i+=4\nDitto above about moving $4 into AX.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode114\nsrc/pkg/math/big/arith_amd64.s:114: ADDL $1, BX\t\t// i++\nINCL BX, like above.",
			"disapproval": false,
			"date": "2012-08-21 21:42:57.126040",
			"approval": false
		},
		{
			"sender": "nigeltao@golang.org",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode38\nsrc/pkg/math/big/arith_amd64.s:38: MOVQ $0, BX\t\t// i = 0\nOn 2012/08/21 21:42:57, Christopher Swenson wrote:\n> This instruction is 7 bytes long, whereas XOR BX, BX is only 3.\n\nI forget exactly where in 6g/6l it happens, but \"MOVQ $0, BX\" gets rewritten to \"XORQ BX, BX\".",
			"disapproval": false,
			"date": "2012-08-22 01:32:39.640730",
			"approval": false
		},
		{
			"sender": "nigeltao@golang.org",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode37\nsrc/pkg/math/big/arith_amd64.s:37: SHLQ $2, CX             // CX = (n/4)*4\nShould the SHRQ/SHLQ be \"ANDQ $~3, CX\"? objdump -d tells me that ANDQ is 4 bytes and two shifts are 4+4 bytes:\n\n  400c87:       48 c1 e8 02             shr    $0x2,%rax\n  400c8b:       48 c1 e0 02             shl    $0x2,%rax\n  400c8f:       48 83 e0 fc             and    $0xfffffffffffffffc,%rax",
			"disapproval": false,
			"date": "2012-08-22 01:55:47.293580",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2012/08/22 03:44:59, remyoudompheng wrote:\n> I am currently working on a FFT-based implementation.\n\nI sent an e-mail a few days ago about this: it is implemented externally: https://github.com/remyoudompheng/bigfft",
			"disapproval": false,
			"date": "2012-08-22 03:45:44.414830",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "FYI: I just submitted\r\nhttp://codereview.appspot.com/**6478055/<http://codereview.appspot.com/6478055/>\r\nwhich\r\ncontains benchmarks for some of the core vector routines. They measure the\r\nroutines more precisely and thus permit more accurate tuning.\r\n\r\nI also experimented a bit with DECQ and I can confirm that simply using\r\nDECQ reg (rather then SUBQ $1, reg) makes the code 2x slower. I suspect\r\nthat for DECQ the condition code might not be readily available for the\r\nnext instruction (Jcc) and cause a bad pipeline bubble. Anyway, the lesson\r\nis to avoid it.\r\n\r\nUnless you beat me to it, I may have some rather fast versions of addVV and\r\nsubVV later tonight.\r\n\r\n- gri\r\n\r\n\r\nOn Wed, Aug 22, 2012 at 11:58 PM, <remyoudompheng@gmail.com> wrote:\r\n\r\n> For some reason here DECQ/JNZ is 2x times slower than CMPQ/JL (for both\r\n> rolled/unrolled versions), I'm not sure why. Maybe someone can find an\r\n> architecture where it runs faster?\r\n>\r\n> http://codereview.appspot.com/**6446165/<http://codereview.appspot.com/6446165/>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-08-23 23:00:42.633030",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "There you go! Used to be true in 1994, and it's still true :-)\r\n- gri\r\n\r\n\r\nOn Thu, Aug 23, 2012 at 4:24 PM, Ian Lance Taylor <iant@google.com> wrote:\r\n\r\n> On Thu, Aug 23, 2012 at 4:00 PM, Robert Griesemer <gri@golang.org> wrote:\r\n> >\r\n> > I also experimented a bit with DECQ and I can confirm that simply using\r\n> DECQ\r\n> > reg (rather then SUBQ $1, reg) makes the code 2x slower. I suspect that\r\n> for\r\n> > DECQ the condition code might not be readily available for the next\r\n> > instruction (Jcc) and cause a bad pipeline bubble. Anyway, the lesson is\r\n> to\r\n> > avoid it.\r\n>\r\n> The Intel optimization manual says:\r\n>\r\n>     The inc and dec instructions modify only a subset of the bits in the\r\n> flag\r\n>     register. This creates a dependence on all previous writes of the flag\r\n>     register. This is especially problematic when these instructions are on\r\n>     the critical path because they are used to change an address for a\r\n> load on\r\n>     which many other instructions depend.\r\n>\r\n>     Assembly/Compiler Coding Rule 42. (M impact, H generality) inc and\r\n>     dec instructions should be replaced with an add or sub instruction,\r\n> because\r\n>     add and sub overwrite all flags, whereas inc and dec do not, therefore\r\n>     creating false dependencies on earlier instructions that set the flags.\r\n>\r\n> Ian\r\n>\r\n",
			"disapproval": false,
			"date": "2012-08-23 23:26:45.378030",
			"approval": false
		},
		{
			"sender": "r@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "The 'linkers' (6l etc.) turn the pseudo-ops into the best instruction\r\nfor the job. The assemblers are a peculiar mix of literal instructions\r\nand pseudo-ops like MOV, but the correspondence with machine\r\ninstructions can sometimes be unpredictable.  Best to disassemble a\r\nbinary or run 6l -a to see what happens.\r\n\r\n-rob\r\n",
			"disapproval": false,
			"date": "2012-08-22 02:16:17.840770",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On 2012/08/21 21:42:11, Christopher Swenson wrote:\n> Though, when we are talking about 1Mb+ numbers for multiplication, we should\n> really look into Toom-Cook multiplication, or even an FFT-based multiply.\n\nI am currently working on a FFT-based implementation. It may not be finished but it is already working, and gets closer to GMP performance after applying this CL (1.2-1.5x slower, 2x slower for very large inputs where the algorithm should be recursive but is not yet).\n\nThe assembly routines are the most deterministic improvement I can find at the moment.",
			"disapproval": false,
			"date": "2012-08-22 03:44:59.613100",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"iant@google.com",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "*** Abandoned ***",
			"disapproval": false,
			"date": "2012-08-24 19:26:50.422590",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Good to know (MOVLQZX). So the first instructions can be:\r\n\r\n        MOVL n+8(FP), CX\r\n        TESTQ CX, CX\r\n        JZ E1\r\n\r\n\r\nOn Wed, Aug 22, 2012 at 9:36 PM, <nigeltao@golang.org> wrote:\r\n\r\n>\r\n> http://codereview.appspot.com/**6446165/diff/5/src/pkg/math/**\r\n> big/arith_amd64.s<http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s>\r\n> File src/pkg/math/big/arith_amd64.s (right):\r\n>\r\n> http://codereview.appspot.com/**6446165/diff/5/src/pkg/math/**\r\n> big/arith_amd64.s#newcode30<http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode30>\r\n> src/pkg/math/big/arith_amd64.**s:30: TEXT \u00b7addVV(SB),7,$0\r\n> On 2012/08/22 23:35:02, gri wrote:\r\n>\r\n>>         MOVL n+8(FP), CX\r\n>>         ANDQ $0x00000000ffffffff, CX // \"sign-extension\" (TODO determine\r\n>>\r\n> correct MOV w/\r\n>\r\n>> sign extension instruction)\r\n>>\r\n>\r\n> \"MOVL n+8(FP), CX\" will fill the top 32 bits of CX with zeroes; the MOVL\r\n> is equivalent to a MOVLQZX. If you need sign extension, say \"MOVLQSX\r\n> n+8(FP), CX\".\r\n>\r\n> http://codereview.appspot.com/**6446165/<http://codereview.appspot.com/6446165/>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-08-23 05:18:39.780790",
			"approval": false
		},
		{
			"sender": "cswenson@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Could case b) be helped by using prefetching? I would guess that loop\r\nprediction + prefetching might be good enough to make up the difference for\r\nmost superscalar chips (at least, I've heard Intel claim such things).\r\n\r\nI also wonder how the benchmarks differ on different Intel and AMD chips.\r\n\r\n--Christopher\r\n\r\n\r\nOn Thu, Aug 23, 2012 at 11:32 AM, Robert Griesemer <gri@golang.org> wrote:\r\n\r\n> It may well be that DECQ/JNZ is slower than CMPQ/JL. It used to be the\r\n> case a very long time ago (first Pentiums) that some of the fancier\r\n> instructions that ran longer sequences of micro-instructions  (e.g. LOOP)\r\n> were significantly slower than a much longer equivalent sequence of more\r\n> basic \"RISC\" instructions - and that one was best advised to just stick to\r\n> the very basic instructions. I was hoping this might have changed, and I am\r\n> a bit surprised at DECQ being a problem, but I haven't measured myself yet.\r\n> Also, different architectures may have wildly different results, but we\r\n> should probably stick to some of the newer machines.\r\n>\r\n> Either way, this is why it's important to measure just the assembly\r\n> routines in the benchmark so we have a clear(er) picture. I think the\r\n> effects on execution time we are going to see with these routines are a)\r\n> cycle count for small vectors (data is in cache); b) memory latency for\r\n> large vectors (data is in uncached memory); and c) various variations of\r\n> the three. Unrolling will mostly be beneficial for case b) because extra\r\n> memory fetches are overlapping outstanding ones.\r\n>\r\n> - gri\r\n>\r\n>\r\n> On Wed, Aug 22, 2012 at 11:58 PM, <remyoudompheng@gmail.com> wrote:\r\n>\r\n>> For some reason here DECQ/JNZ is 2x times slower than CMPQ/JL (for both\r\n>> rolled/unrolled versions), I'm not sure why. Maybe someone can find an\r\n>> architecture where it runs faster?\r\n>>\r\n>> http://codereview.appspot.com/**6446165/<http://codereview.appspot.com/6446165/>\r\n>>\r\n>\r\n>\r\n\r\n\r\n-- \r\nChristopher Swenson\r\ncswenson@google.com\r\n",
			"disapproval": false,
			"date": "2012-08-23 15:49:59.814400",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Thanks for working on this.\n\nI think the assembly code can be made more tight. Also, the tests should be arith-specific.\n\n- gri\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode30\nsrc/pkg/math/big/arith_amd64.s:30: TEXT \u00b7addVV(SB),7,$0\nThis can be much improved. I'd like to see almost 0% slow-down for the short vectors. For one, here's a routine that does what we have now with less code (and no need to shuffle around carry bits).\n\nThe unrolled version should be along the same lines.\n\n// func addVV(z, x, y []Word) (c Word)\nTEXT \u00b7addVV(SB),7,$0\n\tMOVQ z+0(FP), R10\n\tMOVQ x+16(FP), R8\n\tMOVQ y+32(FP), R9\n\tMOVL n+8(FP), CX\n\tANDQ $0x00000000ffffffff, CX // \"sign-extension\" (TODO determine correct MOV w/ sign extension instruction)\n\t\n\tMOVQ $0, DX\n\tTESTQ CX, CX\n\tJZ E1\n\n\tMOVQ $0, BX\t\t// i = 0\n\tCLC\n\t\nL1:\tMOVQ (R8)(BX*8), AX\n\tADCQ (R9)(BX*8), AX\n\tMOVQ AX, (R10)(BX*8)\n\t\n\tINCQ BX\t\t// i++\n\tLOOP L1         // n--\n\n\tADCQ $0, DX\n\nE1:\tMOVQ DX, c+48(FP)\n\tRET\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go\nFile src/pkg/math/big/nat_test.go (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode214\nsrc/pkg/math/big/nat_test.go:214: func benchmarkAdd(b *testing.B, sizex, sizey int) {\nYou always provide the same size below for x and y - so just pass one argument. If it needs to change later, it's trivially changed, but for now it's not necessary.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode217\nsrc/pkg/math/big/nat_test.go:217: b.ResetTimer()\nyou should do this immediately before the loop, otherwise you are also measuring the SetBits operation.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode222\nsrc/pkg/math/big/nat_test.go:222: _ = z.Add(&x, &y)\nThese benchmarks are explicitly testing the performance of a handfull a few assembly routines. Should call them directly. Otherwise, when other (Go) improvements to Add and Mul are made, the benchmark results are not comparable anymore.\n\nSpecifically, the overhead for small numbers (1-5 words) is so large that the assembly code barely matters - they almost all use the same amount of time (around 50ns on your machine, around 43ns on mine). Thus, you are not measuring your code. (It is correct that at the end we care about the top-level operations, but these are the low-level primitives that might be used in a variety of situations. We need to measure them alone.)\n\nThese tests (in modified form) should be in arith_test.go.\n\nAlso, to try to compensate for caching effects, it might be useful to run one operation outside the measured loop.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode226\nsrc/pkg/math/big/nat_test.go:226: func benchmarkMul(b *testing.B, sizex, sizey int) {\nsame comments apply here\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode241\nsrc/pkg/math/big/nat_test.go:241: func BenchmarkAdd_100kb(b *testing.B) { benchmarkAdd(b, 100e3, 100e3) }\n100<10\n\n(1kb == 1<<10)\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode242\nsrc/pkg/math/big/nat_test.go:242: func BenchmarkAdd_1Mb(b *testing.B)   { benchmarkAdd(b, 1e6, 1e6) }\n1<<20\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/nat_test.go#newcode243\nsrc/pkg/math/big/nat_test.go:243: func BenchmarkAdd_5Mb(b *testing.B)   { benchmarkAdd(b, 5e6, 5e6) }\nI might be wrong, but going past 100kb sized numbers is not really important for all practical purposes. But more importantly, the benchmark results are likely dominated by memory latency (the improvements drop significantly).\n\n It's more important that some of the \"smaller\" numbers perform reasonably well. In particular, ideally there should be almost no slowdown (less than 5%) for any size due to this change. Please test the following sizes:\n\n1w\n2w\n5w\n10w\n50w\n1Kb\n10Kb\n100Kb\n\nAlso 1Kb == 1024.",
			"disapproval": false,
			"date": "2012-08-22 23:35:02.688810",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "For some reason here DECQ/JNZ is 2x times slower than CMPQ/JL (for both rolled/unrolled versions), I'm not sure why. Maybe someone can find an architecture where it runs faster?",
			"disapproval": false,
			"date": "2012-08-23 06:58:28.740870",
			"approval": false
		},
		{
			"sender": "nigeltao@golang.org",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "http://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode30\nsrc/pkg/math/big/arith_amd64.s:30: TEXT \u00b7addVV(SB),7,$0\nOn 2012/08/22 23:35:02, gri wrote:\n> \tMOVL n+8(FP), CX\n> \tANDQ $0x00000000ffffffff, CX // \"sign-extension\" (TODO determine correct MOV w/\n> sign extension instruction)\n\n\"MOVL n+8(FP), CX\" will fill the top 32 bits of CX with zeroes; the MOVL is equivalent to a MOVLQZX. If you need sign extension, say \"MOVLQSX n+8(FP), CX\".",
			"disapproval": false,
			"date": "2012-08-23 04:36:30.677200",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "FYI.\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s\nFile src/pkg/math/big/arith_amd64.s (right):\n\nhttp://codereview.appspot.com/6446165/diff/5/src/pkg/math/big/arith_amd64.s#newcode30\nsrc/pkg/math/big/arith_amd64.s:30: TEXT \u00b7addVV(SB),7,$0\nHere's a version which has even less setup instructions (and the same tight inner loop):\n\n// func addVV(z, x, y []Word) (c Word)\nTEXT \u00b7addVV(SB),7,$0\n        MOVL n+8(FP), CX\t// 32bit n\n        ANDQ $0xffffffff, CX\t// 64bit n; CF = 0; ZF = (n == 0)\n\tJZ E1\t\t\t// if n == 0 goto E1\n\t// CX != 0 && CF == 0\n\t\n\t// initialize pointers to x, y, z\n        MOVQ x+16(FP), R8\n        MOVQ y+32(FP), R9\n        MOVQ z+0(FP), R10\n\n        MOVQ $0, BX\t\t// i := 0\n\t// CX != 0 && CF == 0\n\nL1:     MOVQ (R8)(BX*8), AX\n        ADCQ (R9)(BX*8), AX\n        MOVQ AX, (R10)(BX*8)\n        \n        INCQ BX\t\t\t// i++, CF unchanged\n\t// Note: The LOOP instruction can be replaced with\n\t//\tDECQ CX\n\t//\tJNZ L1\n\t// if they run faster then the LOOP microcode.\n        LOOP L1\t\t\t// n--; if n != 0 goto L1\n\t// CX == 0\n\n        ADCQ $0, CX\t\t// CX = carry\n\nE1:     MOVQ CX, c+48(FP)\t// return carry\n        RET\n\t\n\t\nI'd like to see this code integrated with the unrolled loop body. You need to check for the case n >= 4 and that can be done with just 2 extra instructions in the standard path:\n\nAfter the initialization of BX (i := 0), you need:\n\n\tTESTQ $-4, CX\t// if n&0xff..ffC == 0 (i.e., n < 4) goto L1, CF = 0\n\tJZ L1\n\t// CX >= 4 && CF == 0\n\n\t... unrolled loop code here ...\n\nL1:\tMOVQ (R8)(BX*8), AX\n\t...",
			"disapproval": false,
			"date": "2012-08-23 05:10:17.267190",
			"approval": false
		},
		{
			"sender": "gri@golang.org",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "It may well be that DECQ/JNZ is slower than CMPQ/JL. It used to be the case\r\na very long time ago (first Pentiums) that some of the fancier instructions\r\nthat ran longer sequences of micro-instructions  (e.g. LOOP) were\r\nsignificantly slower than a much longer equivalent sequence of more basic\r\n\"RISC\" instructions - and that one was best advised to just stick to the\r\nvery basic instructions. I was hoping this might have changed, and I am a\r\nbit surprised at DECQ being a problem, but I haven't measured myself yet.\r\nAlso, different architectures may have wildly different results, but we\r\nshould probably stick to some of the newer machines.\r\n\r\nEither way, this is why it's important to measure just the assembly\r\nroutines in the benchmark so we have a clear(er) picture. I think the\r\neffects on execution time we are going to see with these routines are a)\r\ncycle count for small vectors (data is in cache); b) memory latency for\r\nlarge vectors (data is in uncached memory); and c) various variations of\r\nthe three. Unrolling will mostly be beneficial for case b) because extra\r\nmemory fetches are overlapping outstanding ones.\r\n\r\n- gri\r\n\r\n\r\nOn Wed, Aug 22, 2012 at 11:58 PM, <remyoudompheng@gmail.com> wrote:\r\n\r\n> For some reason here DECQ/JNZ is 2x times slower than CMPQ/JL (for both\r\n> rolled/unrolled versions), I'm not sure why. Maybe someone can find an\r\n> architecture where it runs faster?\r\n>\r\n> http://codereview.appspot.com/**6446165/<http://codereview.appspot.com/6446165/>\r\n>\r\n",
			"disapproval": false,
			"date": "2012-08-23 15:32:51.416490",
			"approval": false
		},
		{
			"sender": "iant@google.com",
			"recipients": [
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "On Thu, Aug 23, 2012 at 4:00 PM, Robert Griesemer <gri@golang.org> wrote:\r\n>\r\n> I also experimented a bit with DECQ and I can confirm that simply using DECQ\r\n> reg (rather then SUBQ $1, reg) makes the code 2x slower. I suspect that for\r\n> DECQ the condition code might not be readily available for the next\r\n> instruction (Jcc) and cause a bad pipeline bubble. Anyway, the lesson is to\r\n> avoid it.\r\n\r\nThe Intel optimization manual says:\r\n\r\n    The inc and dec instructions modify only a subset of the bits in the flag\r\n    register. This creates a dependence on all previous writes of the flag\r\n    register. This is especially problematic when these instructions are on\r\n    the critical path because they are used to change an address for a load on\r\n    which many other instructions depend.\r\n\r\n    Assembly/Compiler Coding Rule 42. (M impact, H generality) inc and\r\n    dec instructions should be replaced with an add or sub instruction, because\r\n    add and sub overwrite all flags, whereas inc and dec do not, therefore\r\n    creating false dependencies on earlier instructions that set the flags.\r\n\r\nIan\r\n",
			"disapproval": false,
			"date": "2012-08-23 23:24:26.182880",
			"approval": false
		},
		{
			"sender": "remyoudompheng@gmail.com",
			"recipients": [
				"remyoudompheng@gmail.com",
				"gri@golang.org",
				"cswenson@google.com",
				"nigeltao@golang.org",
				"r@golang.org",
				"iant@google.com",
				"golang-dev@googlegroups.com",
				"remy@archlinux.org",
				"reply@codereview-hr.appspotmail.com"
			],
			"text": "Superseded by http://codereview.appspot.com/6482062/",
			"disapproval": false,
			"date": "2012-08-24 19:26:13.437180",
			"approval": false
		}
	],
	"owner_email": "remyoudompheng@gmail.com",
	"private": false,
	"base_url": "",
	"owner": "remyoudompheng",
	"subject": "code review 6446165: math/big: unroll loops a bit in amd64 assembly routines.",
	"created": "2012-08-21 17:53:45.663790",
	"patchsets": [
		1,
		2001,
		5001,
		5
	],
	"modified": "2012-08-24 19:26:52.867000",
	"closed": true,
	"issue": 6446165
}